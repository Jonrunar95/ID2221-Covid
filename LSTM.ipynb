{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import CovidAPI\n",
    "\n",
    "# pip install cassandra-driver\n",
    "from cassandra.cluster import Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cassandra stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(country='Iceland', date='2020-10-23', deathrate=117.99199676513672, newconfirmed=38.0, newdeaths=0.0, population=341250.0, totalconfirmed=4268.0, totaldeaths=11.0)]\n"
     ]
    }
   ],
   "source": [
    "# Get info on single country\n",
    "# country: String with a capital letter\n",
    "def getCountryInfo(country):\n",
    "    prep = session.prepare(\"SELECT * FROM countryinfo WHERE country=?\")\n",
    "    result = session.execute(prep, [country])\n",
    "    return result\n",
    "\n",
    "# Get info on all available countries\n",
    "def getAllCountryInfo():\n",
    "    result = session.execute(\"SELECT * from countryinfo\")\n",
    "    return result\n",
    "\n",
    "cluster = Cluster()\n",
    "session = cluster.connect(\"covid\")\n",
    "print(getCountryInfo(\"Iceland\").all())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not cassandra stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X dimensions: 14\n",
      "No. data points: 226\n"
     ]
    }
   ],
   "source": [
    "def getDataPoints(X, y, countryData):\n",
    "    cases = []\n",
    "    # Only get relevant data\n",
    "    for d in countryData:\n",
    "        cases.append((d[\"Confirmed\"], d[\"Date\"].split(\"T\")[0]))\n",
    "        \n",
    "    # Create data points for X and corresponding y\n",
    "    # For each datapoint 0:N-14\n",
    "    for i in range(len(cases)-14):\n",
    "        timeRange = []\n",
    "        # For selected date n:n+13\n",
    "        for k in range(14):\n",
    "            timeRange.append(cases[i+k][0])\n",
    "        X.append(timeRange)\n",
    "        # Target is 15th day\n",
    "        y.append(cases[i+14][0])\n",
    "    return X, y\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "X = []\n",
    "y = []\n",
    "\n",
    "api = CovidAPI.API()\n",
    "data = api.getDayOneCountry(\"Iceland\")\n",
    "#data = api.getAllCountryCases()\n",
    "#print(data[1])\n",
    "\n",
    "#for d in data:\n",
    "#    X, y = getDataPoints(X, y, d)\n",
    "X, y = getDataPoints(X, y, data)\n",
    "    \n",
    "X = np.asarray(X)#.reshape((len(X), len(X[0]), 1))\n",
    "y = np.asarray(y)#.reshape((len(y), 1))\n",
    "\n",
    "dim = X.shape[1]\n",
    "N = X.shape[0]\n",
    "\n",
    "print(\"X dimensions:\", dim)\n",
    "print(\"No. data points:\", N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (151, 14)\n",
      "y_train shape: (151,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "137/137 [==============================] - 2s 13ms/step - loss: 31438750.0000 - val_loss: 251276240.0000\n",
      "Epoch 2/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 31394610.0000 - val_loss: 251138304.0000\n",
      "Epoch 3/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 31368858.0000 - val_loss: 251022816.0000\n",
      "Epoch 4/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 31345222.0000 - val_loss: 250915248.0000\n",
      "Epoch 5/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 31318748.0000 - val_loss: 250796928.0000\n",
      "Epoch 6/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 31297376.0000 - val_loss: 250683968.0000\n",
      "Epoch 7/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 31272984.0000 - val_loss: 250578048.0000\n",
      "Epoch 8/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 31251240.0000 - val_loss: 250469776.0000\n",
      "Epoch 9/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 31224616.0000 - val_loss: 250350864.0000\n",
      "Epoch 10/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 31203684.0000 - val_loss: 250239408.0000\n",
      "Epoch 11/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 31181916.0000 - val_loss: 250131440.0000\n",
      "Epoch 12/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 31148688.0000 - val_loss: 250016736.0000\n",
      "Epoch 13/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 31132468.0000 - val_loss: 249909696.0000\n",
      "Epoch 14/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 31111004.0000 - val_loss: 249797088.0000\n",
      "Epoch 15/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 31083498.0000 - val_loss: 249688640.0000\n",
      "Epoch 16/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 31066184.0000 - val_loss: 249578112.0000\n",
      "Epoch 17/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 31037422.0000 - val_loss: 249469984.0000\n",
      "Epoch 18/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 31005484.0000 - val_loss: 249359104.0000\n",
      "Epoch 19/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30974876.0000 - val_loss: 249247760.0000\n",
      "Epoch 20/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30970436.0000 - val_loss: 249140288.0000\n",
      "Epoch 21/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30950316.0000 - val_loss: 249033888.0000\n",
      "Epoch 22/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30920484.0000 - val_loss: 248925040.0000\n",
      "Epoch 23/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30907670.0000 - val_loss: 248819072.0000\n",
      "Epoch 24/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30881550.0000 - val_loss: 248709072.0000\n",
      "Epoch 25/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30858758.0000 - val_loss: 248606064.0000\n",
      "Epoch 26/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30827264.0000 - val_loss: 248491952.0000\n",
      "Epoch 27/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30805380.0000 - val_loss: 248386432.0000\n",
      "Epoch 28/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30787560.0000 - val_loss: 248277280.0000\n",
      "Epoch 29/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30761534.0000 - val_loss: 248170208.0000\n",
      "Epoch 30/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30725274.0000 - val_loss: 248063024.0000\n",
      "Epoch 31/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30713354.0000 - val_loss: 247950272.0000\n",
      "Epoch 32/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30700236.0000 - val_loss: 247845456.0000\n",
      "Epoch 33/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30670806.0000 - val_loss: 247740640.0000\n",
      "Epoch 34/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30642726.0000 - val_loss: 247628944.0000\n",
      "Epoch 35/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 30616844.0000 - val_loss: 247521472.0000\n",
      "Epoch 36/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30616070.0000 - val_loss: 247420080.0000\n",
      "Epoch 37/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30588896.0000 - val_loss: 247311600.0000\n",
      "Epoch 38/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30562408.0000 - val_loss: 247206656.0000\n",
      "Epoch 39/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30535160.0000 - val_loss: 247097712.0000\n",
      "Epoch 40/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30517404.0000 - val_loss: 246991568.0000\n",
      "Epoch 41/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30506272.0000 - val_loss: 246887360.0000\n",
      "Epoch 42/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30474202.0000 - val_loss: 246780928.0000\n",
      "Epoch 43/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 30449194.0000 - val_loss: 246674272.0000\n",
      "Epoch 44/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30406630.0000 - val_loss: 246566512.0000\n",
      "Epoch 45/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30415788.0000 - val_loss: 246462592.0000\n",
      "Epoch 46/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30354360.0000 - val_loss: 246357136.0000\n",
      "Epoch 47/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30350064.0000 - val_loss: 246245296.0000\n",
      "Epoch 48/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30366898.0000 - val_loss: 246144016.0000\n",
      "Epoch 49/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30318676.0000 - val_loss: 246036528.0000\n",
      "Epoch 50/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30344462.0000 - val_loss: 245943248.0000\n",
      "Epoch 51/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30279174.0000 - val_loss: 245817520.0000\n",
      "Epoch 52/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30260048.0000 - val_loss: 245712016.0000\n",
      "Epoch 53/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30197226.0000 - val_loss: 245596176.0000\n",
      "Epoch 54/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30181660.0000 - val_loss: 245485792.0000\n",
      "Epoch 55/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30147854.0000 - val_loss: 245375792.0000\n",
      "Epoch 56/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30138030.0000 - val_loss: 245265312.0000\n",
      "Epoch 57/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30120042.0000 - val_loss: 245154576.0000\n",
      "Epoch 58/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30111046.0000 - val_loss: 245048064.0000\n",
      "Epoch 59/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30098968.0000 - val_loss: 244941184.0000\n",
      "Epoch 60/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30044488.0000 - val_loss: 244830848.0000\n",
      "Epoch 61/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30043104.0000 - val_loss: 244728528.0000\n",
      "Epoch 62/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 30028818.0000 - val_loss: 244618896.0000\n",
      "Epoch 63/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 30009652.0000 - val_loss: 244515008.0000\n",
      "Epoch 64/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 29984606.0000 - val_loss: 244408416.0000\n",
      "Epoch 65/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 29969254.0000 - val_loss: 244301248.0000\n",
      "Epoch 66/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 29928334.0000 - val_loss: 244192976.0000\n",
      "Epoch 67/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 29888506.0000 - val_loss: 244082272.0000\n",
      "Epoch 68/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 29904484.0000 - val_loss: 243977024.0000\n",
      "Epoch 69/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 29885820.0000 - val_loss: 243869040.0000\n",
      "Epoch 70/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 29813526.0000 - val_loss: 243762560.0000\n",
      "Epoch 71/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 29809524.0000 - val_loss: 243657264.0000\n",
      "Epoch 72/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 29804270.0000 - val_loss: 243547856.0000\n",
      "Epoch 73/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 29768638.0000 - val_loss: 243442448.0000\n",
      "Epoch 74/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 29784506.0000 - val_loss: 243337552.0000\n",
      "Epoch 75/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 29725828.0000 - val_loss: 243230320.0000\n",
      "Epoch 76/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 29709266.0000 - val_loss: 243127792.0000\n",
      "Epoch 77/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 29731626.0000 - val_loss: 243019328.0000\n",
      "Epoch 78/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 29654960.0000 - val_loss: 242912192.0000\n",
      "Epoch 79/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 29631352.0000 - val_loss: 242806400.0000\n",
      "Epoch 80/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 29602866.0000 - val_loss: 242697728.0000\n",
      "Epoch 81/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 29592138.0000 - val_loss: 242591776.0000\n",
      "Epoch 82/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 29540458.0000 - val_loss: 242483840.0000\n",
      "Epoch 83/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 29584944.0000 - val_loss: 242378976.0000\n",
      "Epoch 84/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 29572622.0000 - val_loss: 242272832.0000\n",
      "Epoch 85/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 29550630.0000 - val_loss: 242173680.0000\n",
      "Epoch 86/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 29480718.0000 - val_loss: 242067008.0000\n",
      "Epoch 87/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 29501662.0000 - val_loss: 241959696.0000\n",
      "Epoch 88/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 29433306.0000 - val_loss: 241854880.0000\n",
      "Epoch 89/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 29411440.0000 - val_loss: 241747568.0000\n",
      "Epoch 90/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 29416488.0000 - val_loss: 241642288.0000\n",
      "Epoch 91/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 29417460.0000 - val_loss: 241535216.0000\n",
      "Epoch 92/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 29335864.0000 - val_loss: 241428368.0000\n",
      "Epoch 93/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 29384336.0000 - val_loss: 241323184.0000\n",
      "Epoch 94/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 29336558.0000 - val_loss: 241219296.0000\n",
      "Epoch 95/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 29340836.0000 - val_loss: 241117744.0000\n",
      "Epoch 96/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 29267172.0000 - val_loss: 241010640.0000\n",
      "Epoch 97/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 29272026.0000 - val_loss: 240907392.0000\n",
      "Epoch 98/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 29284276.0000 - val_loss: 240800880.0000\n",
      "Epoch 99/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 29217308.0000 - val_loss: 240697584.0000\n",
      "Epoch 100/1000\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 29199162.0000 - val_loss: 240597280.0000\n",
      "Epoch 101/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 29120980.0000 - val_loss: 240484736.0000\n",
      "Epoch 102/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 29146032.0000 - val_loss: 240383344.0000\n",
      "Epoch 103/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 29035886.0000 - val_loss: 240273264.0000\n",
      "Epoch 104/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 29176366.0000 - val_loss: 240170544.0000\n",
      "Epoch 105/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 29093646.0000 - val_loss: 240065504.0000\n",
      "Epoch 106/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 29086832.0000 - val_loss: 239966480.0000\n",
      "Epoch 107/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 29036896.0000 - val_loss: 239855040.0000\n",
      "Epoch 108/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 28963876.0000 - val_loss: 239748480.0000\n",
      "Epoch 109/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 29011392.0000 - val_loss: 239644080.0000\n",
      "Epoch 110/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 29027756.0000 - val_loss: 239542304.0000\n",
      "Epoch 111/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 28970044.0000 - val_loss: 239438208.0000\n",
      "Epoch 112/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 28887030.0000 - val_loss: 239336064.0000\n",
      "Epoch 113/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 28989794.0000 - val_loss: 239231936.0000\n",
      "Epoch 114/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 28930578.0000 - val_loss: 239131296.0000\n",
      "Epoch 115/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 28897108.0000 - val_loss: 239027728.0000\n",
      "Epoch 116/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 28852858.0000 - val_loss: 238922928.0000\n",
      "Epoch 117/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 28899378.0000 - val_loss: 238821472.0000\n",
      "Epoch 118/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 28800126.0000 - val_loss: 238712384.0000\n",
      "Epoch 119/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 28780332.0000 - val_loss: 238611008.0000\n",
      "Epoch 120/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 28824688.0000 - val_loss: 238506176.0000\n",
      "Epoch 121/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 28723754.0000 - val_loss: 238400176.0000\n",
      "Epoch 122/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 28783476.0000 - val_loss: 238298240.0000\n",
      "Epoch 123/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 28713490.0000 - val_loss: 238197488.0000\n",
      "Epoch 124/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 28737536.0000 - val_loss: 238093440.0000\n",
      "Epoch 125/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 28722698.0000 - val_loss: 237991504.0000\n",
      "Epoch 126/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 28638582.0000 - val_loss: 237887200.0000\n",
      "Epoch 127/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 28665620.0000 - val_loss: 237785632.0000\n",
      "Epoch 128/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 28619384.0000 - val_loss: 237682864.0000\n",
      "Epoch 129/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 28619984.0000 - val_loss: 237578928.0000\n",
      "Epoch 130/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 28593356.0000 - val_loss: 237475712.0000\n",
      "Epoch 131/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 28521778.0000 - val_loss: 237369488.0000\n",
      "Epoch 132/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 28491524.0000 - val_loss: 237267328.0000\n",
      "Epoch 133/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 28479424.0000 - val_loss: 237164368.0000\n",
      "Epoch 134/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 28544414.0000 - val_loss: 237063808.0000\n",
      "Epoch 135/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 28457748.0000 - val_loss: 236961312.0000\n",
      "Epoch 136/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 28475308.0000 - val_loss: 236860576.0000\n",
      "Epoch 137/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 28453162.0000 - val_loss: 236754192.0000\n",
      "Epoch 138/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 28465012.0000 - val_loss: 236654304.0000\n",
      "Epoch 139/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 1s 9ms/step - loss: 28393778.0000 - val_loss: 236550368.0000\n",
      "Epoch 140/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 28352282.0000 - val_loss: 236448240.0000\n",
      "Epoch 141/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 28327950.0000 - val_loss: 236350400.0000\n",
      "Epoch 142/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 28340936.0000 - val_loss: 236244704.0000\n",
      "Epoch 143/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 28326356.0000 - val_loss: 236138112.0000\n",
      "Epoch 144/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 28325502.0000 - val_loss: 236038672.0000\n",
      "Epoch 145/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 28247554.0000 - val_loss: 235936528.0000\n",
      "Epoch 146/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 28239560.0000 - val_loss: 235832832.0000\n",
      "Epoch 147/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 28216368.0000 - val_loss: 235734464.0000\n",
      "Epoch 148/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 28158736.0000 - val_loss: 235629872.0000\n",
      "Epoch 149/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 28144340.0000 - val_loss: 235523792.0000\n",
      "Epoch 150/1000\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 28108636.0000 - val_loss: 235418688.0000\n",
      "Epoch 151/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 28099662.0000 - val_loss: 235320464.0000\n",
      "Epoch 152/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 28214390.0000 - val_loss: 235221504.0000\n",
      "Epoch 153/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 28053606.0000 - val_loss: 235118288.0000\n",
      "Epoch 154/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 28099814.0000 - val_loss: 235020464.0000\n",
      "Epoch 155/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 28071466.0000 - val_loss: 234915040.0000\n",
      "Epoch 156/1000\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 28046224.0000 - val_loss: 234812096.0000\n",
      "Epoch 157/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 28052588.0000 - val_loss: 234711680.0000\n",
      "Epoch 158/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 27995416.0000 - val_loss: 234610960.0000\n",
      "Epoch 159/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 27960892.0000 - val_loss: 234506064.0000\n",
      "Epoch 160/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 28001540.0000 - val_loss: 234405680.0000\n",
      "Epoch 161/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 27978618.0000 - val_loss: 234305408.0000\n",
      "Epoch 162/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 27894482.0000 - val_loss: 234203056.0000\n",
      "Epoch 163/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27937600.0000 - val_loss: 234101760.0000\n",
      "Epoch 164/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 27917662.0000 - val_loss: 234001952.0000\n",
      "Epoch 165/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27951664.0000 - val_loss: 233904176.0000\n",
      "Epoch 166/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27845182.0000 - val_loss: 233804480.0000\n",
      "Epoch 167/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27855556.0000 - val_loss: 233702384.0000\n",
      "Epoch 168/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27824062.0000 - val_loss: 233603584.0000\n",
      "Epoch 169/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27774058.0000 - val_loss: 233499008.0000\n",
      "Epoch 170/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27817472.0000 - val_loss: 233403280.0000\n",
      "Epoch 171/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27791482.0000 - val_loss: 233298672.0000\n",
      "Epoch 172/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 27779402.0000 - val_loss: 233199184.0000\n",
      "Epoch 173/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 27728204.0000 - val_loss: 233099952.0000\n",
      "Epoch 174/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 27755550.0000 - val_loss: 233000352.0000\n",
      "Epoch 175/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27697250.0000 - val_loss: 232899968.0000\n",
      "Epoch 176/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27621080.0000 - val_loss: 232800816.0000\n",
      "Epoch 177/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27640582.0000 - val_loss: 232697184.0000\n",
      "Epoch 178/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27631428.0000 - val_loss: 232598768.0000\n",
      "Epoch 179/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27624394.0000 - val_loss: 232496176.0000\n",
      "Epoch 180/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27533534.0000 - val_loss: 232396224.0000\n",
      "Epoch 181/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27542462.0000 - val_loss: 232294672.0000\n",
      "Epoch 182/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27535876.0000 - val_loss: 232192272.0000\n",
      "Epoch 183/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27492592.0000 - val_loss: 232097456.0000\n",
      "Epoch 184/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27503038.0000 - val_loss: 231996832.0000\n",
      "Epoch 185/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 27475076.0000 - val_loss: 231895680.0000\n",
      "Epoch 186/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27395802.0000 - val_loss: 231797552.0000\n",
      "Epoch 187/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 27458026.0000 - val_loss: 231694320.0000\n",
      "Epoch 188/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27455900.0000 - val_loss: 231597696.0000\n",
      "Epoch 189/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27380148.0000 - val_loss: 231498032.0000\n",
      "Epoch 190/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 27458730.0000 - val_loss: 231394944.0000\n",
      "Epoch 191/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 27368570.0000 - val_loss: 231299952.0000\n",
      "Epoch 192/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 27389588.0000 - val_loss: 231197856.0000\n",
      "Epoch 193/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27370038.0000 - val_loss: 231099184.0000\n",
      "Epoch 194/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27271686.0000 - val_loss: 230996768.0000\n",
      "Epoch 195/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27311004.0000 - val_loss: 230898688.0000\n",
      "Epoch 196/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27189498.0000 - val_loss: 230799936.0000\n",
      "Epoch 197/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27265514.0000 - val_loss: 230699680.0000\n",
      "Epoch 198/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27254974.0000 - val_loss: 230603520.0000\n",
      "Epoch 199/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27248554.0000 - val_loss: 230501248.0000\n",
      "Epoch 200/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 27197516.0000 - val_loss: 230401920.0000\n",
      "Epoch 201/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27195498.0000 - val_loss: 230302880.0000\n",
      "Epoch 202/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27120784.0000 - val_loss: 230204816.0000\n",
      "Epoch 203/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27185992.0000 - val_loss: 230109792.0000\n",
      "Epoch 204/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27161366.0000 - val_loss: 230011248.0000\n",
      "Epoch 205/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27137798.0000 - val_loss: 229909968.0000\n",
      "Epoch 206/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27061440.0000 - val_loss: 229810496.0000\n",
      "Epoch 207/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27070902.0000 - val_loss: 229712464.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26945810.0000 - val_loss: 229611216.0000\n",
      "Epoch 209/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 26943936.0000 - val_loss: 229507600.0000\n",
      "Epoch 210/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 27047400.0000 - val_loss: 229410448.0000\n",
      "Epoch 211/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27082250.0000 - val_loss: 229315408.0000\n",
      "Epoch 212/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 27002760.0000 - val_loss: 229213056.0000\n",
      "Epoch 213/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26889418.0000 - val_loss: 229120944.0000\n",
      "Epoch 214/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 26833470.0000 - val_loss: 229016880.0000\n",
      "Epoch 215/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26870048.0000 - val_loss: 228920304.0000\n",
      "Epoch 216/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26885156.0000 - val_loss: 228819840.0000\n",
      "Epoch 217/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26780614.0000 - val_loss: 228724080.0000\n",
      "Epoch 218/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26800314.0000 - val_loss: 228620032.0000\n",
      "Epoch 219/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26824120.0000 - val_loss: 228523904.0000\n",
      "Epoch 220/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 26834540.0000 - val_loss: 228425088.0000\n",
      "Epoch 221/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26725436.0000 - val_loss: 228325216.0000\n",
      "Epoch 222/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26679458.0000 - val_loss: 228226256.0000\n",
      "Epoch 223/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26741552.0000 - val_loss: 228127056.0000\n",
      "Epoch 224/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26772070.0000 - val_loss: 228033920.0000\n",
      "Epoch 225/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26679598.0000 - val_loss: 227932480.0000\n",
      "Epoch 226/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26618880.0000 - val_loss: 227834288.0000\n",
      "Epoch 227/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26700428.0000 - val_loss: 227738944.0000\n",
      "Epoch 228/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26637210.0000 - val_loss: 227638400.0000\n",
      "Epoch 229/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26563138.0000 - val_loss: 227540928.0000\n",
      "Epoch 230/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26675578.0000 - val_loss: 227446464.0000\n",
      "Epoch 231/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26563858.0000 - val_loss: 227345360.0000\n",
      "Epoch 232/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26444418.0000 - val_loss: 227244848.0000\n",
      "Epoch 233/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26600844.0000 - val_loss: 227150448.0000\n",
      "Epoch 234/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26555238.0000 - val_loss: 227056112.0000\n",
      "Epoch 235/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26486464.0000 - val_loss: 226954800.0000\n",
      "Epoch 236/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26492300.0000 - val_loss: 226855808.0000\n",
      "Epoch 237/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 26446404.0000 - val_loss: 226759776.0000\n",
      "Epoch 238/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26563138.0000 - val_loss: 226660096.0000\n",
      "Epoch 239/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 26557720.0000 - val_loss: 226566896.0000\n",
      "Epoch 240/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 26472088.0000 - val_loss: 226473024.0000\n",
      "Epoch 241/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 26381000.0000 - val_loss: 226370352.0000\n",
      "Epoch 242/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26428872.0000 - val_loss: 226275520.0000\n",
      "Epoch 243/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26390738.0000 - val_loss: 226178704.0000\n",
      "Epoch 244/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26245828.0000 - val_loss: 226077824.0000\n",
      "Epoch 245/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26443148.0000 - val_loss: 225984080.0000\n",
      "Epoch 246/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26280268.0000 - val_loss: 225887328.0000\n",
      "Epoch 247/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26261074.0000 - val_loss: 225788704.0000\n",
      "Epoch 248/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26404796.0000 - val_loss: 225692544.0000\n",
      "Epoch 249/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26177670.0000 - val_loss: 225595088.0000\n",
      "Epoch 250/1000\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 26288900.0000 - val_loss: 225502736.0000\n",
      "Epoch 251/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26164970.0000 - val_loss: 225405952.0000\n",
      "Epoch 252/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26217474.0000 - val_loss: 225304112.0000\n",
      "Epoch 253/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26076036.0000 - val_loss: 225205568.0000\n",
      "Epoch 254/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26139386.0000 - val_loss: 225110704.0000\n",
      "Epoch 255/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26318632.0000 - val_loss: 225018512.0000\n",
      "Epoch 256/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26110084.0000 - val_loss: 224916688.0000\n",
      "Epoch 257/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 26025430.0000 - val_loss: 224823472.0000\n",
      "Epoch 258/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 26114222.0000 - val_loss: 224726000.0000\n",
      "Epoch 259/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25981824.0000 - val_loss: 224627616.0000\n",
      "Epoch 260/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 26065968.0000 - val_loss: 224532800.0000\n",
      "Epoch 261/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26173810.0000 - val_loss: 224436832.0000\n",
      "Epoch 262/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26064288.0000 - val_loss: 224343648.0000\n",
      "Epoch 263/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26074696.0000 - val_loss: 224249344.0000\n",
      "Epoch 264/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25934340.0000 - val_loss: 224151920.0000\n",
      "Epoch 265/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25954420.0000 - val_loss: 224057520.0000\n",
      "Epoch 266/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26017776.0000 - val_loss: 223965440.0000\n",
      "Epoch 267/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 26008870.0000 - val_loss: 223865488.0000\n",
      "Epoch 268/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25878492.0000 - val_loss: 223769040.0000\n",
      "Epoch 269/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25870334.0000 - val_loss: 223674960.0000\n",
      "Epoch 270/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25968598.0000 - val_loss: 223579280.0000\n",
      "Epoch 271/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25867878.0000 - val_loss: 223483008.0000\n",
      "Epoch 272/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25775482.0000 - val_loss: 223387008.0000\n",
      "Epoch 273/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25787292.0000 - val_loss: 223291088.0000\n",
      "Epoch 274/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25864474.0000 - val_loss: 223196960.0000\n",
      "Epoch 275/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25781272.0000 - val_loss: 223096832.0000\n",
      "Epoch 276/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25879248.0000 - val_loss: 223005520.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25796510.0000 - val_loss: 222905440.0000\n",
      "Epoch 278/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25812362.0000 - val_loss: 222816720.0000\n",
      "Epoch 279/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25707314.0000 - val_loss: 222716672.0000\n",
      "Epoch 280/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25738170.0000 - val_loss: 222621840.0000\n",
      "Epoch 281/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25815936.0000 - val_loss: 222533152.0000\n",
      "Epoch 282/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25715992.0000 - val_loss: 222434496.0000\n",
      "Epoch 283/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25763920.0000 - val_loss: 222343712.0000\n",
      "Epoch 284/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25801628.0000 - val_loss: 222251296.0000\n",
      "Epoch 285/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25662634.0000 - val_loss: 222154576.0000\n",
      "Epoch 286/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 25778436.0000 - val_loss: 222064848.0000\n",
      "Epoch 287/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 25815714.0000 - val_loss: 221973664.0000\n",
      "Epoch 288/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 25503536.0000 - val_loss: 221871696.0000\n",
      "Epoch 289/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 25568584.0000 - val_loss: 221778416.0000\n",
      "Epoch 290/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25493390.0000 - val_loss: 221680672.0000\n",
      "Epoch 291/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25574102.0000 - val_loss: 221590288.0000\n",
      "Epoch 292/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 25632942.0000 - val_loss: 221493360.0000\n",
      "Epoch 293/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 25483614.0000 - val_loss: 221400912.0000\n",
      "Epoch 294/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 25627172.0000 - val_loss: 221306720.0000\n",
      "Epoch 295/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25449122.0000 - val_loss: 221213632.0000\n",
      "Epoch 296/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 25527510.0000 - val_loss: 221116592.0000\n",
      "Epoch 297/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 25397844.0000 - val_loss: 221026032.0000\n",
      "Epoch 298/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 25509642.0000 - val_loss: 220930976.0000\n",
      "Epoch 299/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 25443154.0000 - val_loss: 220837648.0000\n",
      "Epoch 300/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 25384554.0000 - val_loss: 220740480.0000\n",
      "Epoch 301/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 25334682.0000 - val_loss: 220648304.0000\n",
      "Epoch 302/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 25424412.0000 - val_loss: 220555408.0000\n",
      "Epoch 303/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25409098.0000 - val_loss: 220460160.0000\n",
      "Epoch 304/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25341780.0000 - val_loss: 220369552.0000\n",
      "Epoch 305/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25270182.0000 - val_loss: 220274144.0000\n",
      "Epoch 306/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25315748.0000 - val_loss: 220177008.0000\n",
      "Epoch 307/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25325416.0000 - val_loss: 220085200.0000\n",
      "Epoch 308/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25305196.0000 - val_loss: 219993184.0000\n",
      "Epoch 309/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25150108.0000 - val_loss: 219895008.0000\n",
      "Epoch 310/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25237450.0000 - val_loss: 219801536.0000\n",
      "Epoch 311/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 25190214.0000 - val_loss: 219710144.0000\n",
      "Epoch 312/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25183172.0000 - val_loss: 219620112.0000\n",
      "Epoch 313/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25268534.0000 - val_loss: 219526000.0000\n",
      "Epoch 314/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25171688.0000 - val_loss: 219430448.0000\n",
      "Epoch 315/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25097700.0000 - val_loss: 219337552.0000\n",
      "Epoch 316/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25051318.0000 - val_loss: 219239600.0000\n",
      "Epoch 317/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 25157938.0000 - val_loss: 219148832.0000\n",
      "Epoch 318/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 25127816.0000 - val_loss: 219053760.0000\n",
      "Epoch 319/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 24885234.0000 - val_loss: 218962176.0000\n",
      "Epoch 320/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 25075946.0000 - val_loss: 218870224.0000\n",
      "Epoch 321/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 25024798.0000 - val_loss: 218777360.0000\n",
      "Epoch 322/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 24953732.0000 - val_loss: 218684672.0000\n",
      "Epoch 323/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 24949148.0000 - val_loss: 218586352.0000\n",
      "Epoch 324/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 24864066.0000 - val_loss: 218490816.0000\n",
      "Epoch 325/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 24953072.0000 - val_loss: 218400112.0000\n",
      "Epoch 326/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24971380.0000 - val_loss: 218305312.0000\n",
      "Epoch 327/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24976520.0000 - val_loss: 218211648.0000\n",
      "Epoch 328/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24898480.0000 - val_loss: 218123664.0000\n",
      "Epoch 329/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24948004.0000 - val_loss: 218029504.0000\n",
      "Epoch 330/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24609362.0000 - val_loss: 217932032.0000\n",
      "Epoch 331/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24891042.0000 - val_loss: 217845024.0000\n",
      "Epoch 332/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24826458.0000 - val_loss: 217748608.0000\n",
      "Epoch 333/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24809850.0000 - val_loss: 217658592.0000\n",
      "Epoch 334/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24827158.0000 - val_loss: 217567904.0000\n",
      "Epoch 335/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24692694.0000 - val_loss: 217472272.0000\n",
      "Epoch 336/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24655062.0000 - val_loss: 217381040.0000\n",
      "Epoch 337/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24584870.0000 - val_loss: 217283712.0000\n",
      "Epoch 338/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24694974.0000 - val_loss: 217189472.0000\n",
      "Epoch 339/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 24680548.0000 - val_loss: 217096016.0000\n",
      "Epoch 340/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 24679674.0000 - val_loss: 217007280.0000\n",
      "Epoch 341/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24722914.0000 - val_loss: 216914096.0000\n",
      "Epoch 342/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24654982.0000 - val_loss: 216821536.0000\n",
      "Epoch 343/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24711722.0000 - val_loss: 216731776.0000\n",
      "Epoch 344/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24690282.0000 - val_loss: 216638864.0000\n",
      "Epoch 345/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24712880.0000 - val_loss: 216549664.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 346/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24649122.0000 - val_loss: 216453808.0000\n",
      "Epoch 347/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24526536.0000 - val_loss: 216363376.0000\n",
      "Epoch 348/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24547148.0000 - val_loss: 216272160.0000\n",
      "Epoch 349/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24381794.0000 - val_loss: 216178368.0000\n",
      "Epoch 350/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24546314.0000 - val_loss: 216085840.0000\n",
      "Epoch 351/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24573422.0000 - val_loss: 215996544.0000\n",
      "Epoch 352/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24474910.0000 - val_loss: 215898800.0000\n",
      "Epoch 353/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24507776.0000 - val_loss: 215810224.0000\n",
      "Epoch 354/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24710704.0000 - val_loss: 215720240.0000\n",
      "Epoch 355/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24378552.0000 - val_loss: 215629968.0000\n",
      "Epoch 356/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 24333296.0000 - val_loss: 215543552.0000\n",
      "Epoch 357/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24368412.0000 - val_loss: 215442528.0000\n",
      "Epoch 358/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24550238.0000 - val_loss: 215356288.0000\n",
      "Epoch 359/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24221912.0000 - val_loss: 215259488.0000\n",
      "Epoch 360/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 24349240.0000 - val_loss: 215169728.0000\n",
      "Epoch 361/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 24343878.0000 - val_loss: 215078752.0000\n",
      "Epoch 362/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 24416326.0000 - val_loss: 214987216.0000\n",
      "Epoch 363/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24471584.0000 - val_loss: 214902224.0000\n",
      "Epoch 364/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 24249792.0000 - val_loss: 214809088.0000\n",
      "Epoch 365/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 24107652.0000 - val_loss: 214712864.0000\n",
      "Epoch 366/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 24339870.0000 - val_loss: 214621024.0000\n",
      "Epoch 367/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 24304492.0000 - val_loss: 214531104.0000\n",
      "Epoch 368/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 24358152.0000 - val_loss: 214441632.0000\n",
      "Epoch 369/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 24148972.0000 - val_loss: 214352000.0000\n",
      "Epoch 370/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24221414.0000 - val_loss: 214261328.0000\n",
      "Epoch 371/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24049858.0000 - val_loss: 214168032.0000\n",
      "Epoch 372/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24252424.0000 - val_loss: 214076496.0000\n",
      "Epoch 373/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24072972.0000 - val_loss: 213984560.0000\n",
      "Epoch 374/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24116912.0000 - val_loss: 213896048.0000\n",
      "Epoch 375/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24083072.0000 - val_loss: 213799952.0000\n",
      "Epoch 376/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24038614.0000 - val_loss: 213709184.0000\n",
      "Epoch 377/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24112336.0000 - val_loss: 213621616.0000\n",
      "Epoch 378/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 23868236.0000 - val_loss: 213529456.0000\n",
      "Epoch 379/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 24033598.0000 - val_loss: 213435072.0000\n",
      "Epoch 380/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 23932756.0000 - val_loss: 213348976.0000\n",
      "Epoch 381/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 24093288.0000 - val_loss: 213255440.0000\n",
      "Epoch 382/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 24062668.0000 - val_loss: 213166464.0000\n",
      "Epoch 383/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23966704.0000 - val_loss: 213074688.0000\n",
      "Epoch 384/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24055976.0000 - val_loss: 212987424.0000\n",
      "Epoch 385/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24080638.0000 - val_loss: 212897136.0000\n",
      "Epoch 386/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 24110986.0000 - val_loss: 212805760.0000\n",
      "Epoch 387/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23999956.0000 - val_loss: 212718336.0000\n",
      "Epoch 388/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23775118.0000 - val_loss: 212627808.0000\n",
      "Epoch 389/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23858252.0000 - val_loss: 212534320.0000\n",
      "Epoch 390/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 23984528.0000 - val_loss: 212447872.0000\n",
      "Epoch 391/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23740172.0000 - val_loss: 212355760.0000\n",
      "Epoch 392/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23829322.0000 - val_loss: 212266240.0000\n",
      "Epoch 393/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 24038000.0000 - val_loss: 212924112.0000\n",
      "Epoch 394/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23852966.0000 - val_loss: 212089216.0000\n",
      "Epoch 395/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23851162.0000 - val_loss: 211997824.0000\n",
      "Epoch 396/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23854266.0000 - val_loss: 211910096.0000\n",
      "Epoch 397/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23642032.0000 - val_loss: 211820096.0000\n",
      "Epoch 398/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23700468.0000 - val_loss: 211727040.0000\n",
      "Epoch 399/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23576424.0000 - val_loss: 211635088.0000\n",
      "Epoch 400/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23724520.0000 - val_loss: 211546064.0000\n",
      "Epoch 401/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23559746.0000 - val_loss: 211456528.0000\n",
      "Epoch 402/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23537386.0000 - val_loss: 211365792.0000\n",
      "Epoch 403/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23637078.0000 - val_loss: 211273600.0000\n",
      "Epoch 404/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 23643606.0000 - val_loss: 211184400.0000\n",
      "Epoch 405/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23541426.0000 - val_loss: 211088432.0000\n",
      "Epoch 406/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23646456.0000 - val_loss: 211001072.0000\n",
      "Epoch 407/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23477674.0000 - val_loss: 210913840.0000\n",
      "Epoch 408/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23539514.0000 - val_loss: 210825824.0000\n",
      "Epoch 409/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23544400.0000 - val_loss: 210731184.0000\n",
      "Epoch 410/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23420176.0000 - val_loss: 210639968.0000\n",
      "Epoch 411/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23452280.0000 - val_loss: 210548944.0000\n",
      "Epoch 412/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23604624.0000 - val_loss: 210463136.0000\n",
      "Epoch 413/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23506008.0000 - val_loss: 210374048.0000\n",
      "Epoch 414/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23541908.0000 - val_loss: 210284944.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 415/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23561030.0000 - val_loss: 210197920.0000\n",
      "Epoch 416/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23487894.0000 - val_loss: 210110176.0000\n",
      "Epoch 417/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23412896.0000 - val_loss: 210021424.0000\n",
      "Epoch 418/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23232722.0000 - val_loss: 209932624.0000\n",
      "Epoch 419/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23381510.0000 - val_loss: 209841600.0000\n",
      "Epoch 420/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23503884.0000 - val_loss: 211331264.0000\n",
      "Epoch 421/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23497216.0000 - val_loss: 209665056.0000\n",
      "Epoch 422/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23339566.0000 - val_loss: 209579424.0000\n",
      "Epoch 423/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23284128.0000 - val_loss: 209487088.0000\n",
      "Epoch 424/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23308834.0000 - val_loss: 209398144.0000\n",
      "Epoch 425/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23151714.0000 - val_loss: 209310144.0000\n",
      "Epoch 426/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23202952.0000 - val_loss: 209215296.0000\n",
      "Epoch 427/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23190980.0000 - val_loss: 209128256.0000\n",
      "Epoch 428/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23126250.0000 - val_loss: 209038416.0000\n",
      "Epoch 429/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23229104.0000 - val_loss: 208953136.0000\n",
      "Epoch 430/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23281206.0000 - val_loss: 208862992.0000\n",
      "Epoch 431/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23233116.0000 - val_loss: 208776288.0000\n",
      "Epoch 432/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23282200.0000 - val_loss: 208689312.0000\n",
      "Epoch 433/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23169594.0000 - val_loss: 208600992.0000\n",
      "Epoch 434/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23302152.0000 - val_loss: 208511888.0000\n",
      "Epoch 435/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23115528.0000 - val_loss: 208420240.0000\n",
      "Epoch 436/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23207958.0000 - val_loss: 208337232.0000\n",
      "Epoch 437/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23023734.0000 - val_loss: 208245648.0000\n",
      "Epoch 438/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23056438.0000 - val_loss: 208157744.0000\n",
      "Epoch 439/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23210384.0000 - val_loss: 208070032.0000\n",
      "Epoch 440/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23271466.0000 - val_loss: 207984336.0000\n",
      "Epoch 441/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23173702.0000 - val_loss: 207897968.0000\n",
      "Epoch 442/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23105960.0000 - val_loss: 207810528.0000\n",
      "Epoch 443/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23111832.0000 - val_loss: 207725360.0000\n",
      "Epoch 444/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23001682.0000 - val_loss: 207636784.0000\n",
      "Epoch 445/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 22806506.0000 - val_loss: 207542688.0000\n",
      "Epoch 446/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 22997184.0000 - val_loss: 207459552.0000\n",
      "Epoch 447/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 22850974.0000 - val_loss: 207368048.0000\n",
      "Epoch 448/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23091798.0000 - val_loss: 207283536.0000\n",
      "Epoch 449/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23015740.0000 - val_loss: 207194080.0000\n",
      "Epoch 450/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 22823156.0000 - val_loss: 207111440.0000\n",
      "Epoch 451/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22828524.0000 - val_loss: 207019968.0000\n",
      "Epoch 452/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 22833264.0000 - val_loss: 206933712.0000\n",
      "Epoch 453/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 22722296.0000 - val_loss: 206840112.0000\n",
      "Epoch 454/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22831460.0000 - val_loss: 206756288.0000\n",
      "Epoch 455/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22853246.0000 - val_loss: 206665760.0000\n",
      "Epoch 456/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 22866280.0000 - val_loss: 206580624.0000\n",
      "Epoch 457/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 22753864.0000 - val_loss: 206492416.0000\n",
      "Epoch 458/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22850720.0000 - val_loss: 206410784.0000\n",
      "Epoch 459/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 22837896.0000 - val_loss: 206323392.0000\n",
      "Epoch 460/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 23148374.0000 - val_loss: 206235920.0000\n",
      "Epoch 461/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22789978.0000 - val_loss: 206150112.0000\n",
      "Epoch 462/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 23011030.0000 - val_loss: 206064400.0000\n",
      "Epoch 463/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22661708.0000 - val_loss: 205976848.0000\n",
      "Epoch 464/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22933262.0000 - val_loss: 205896816.0000\n",
      "Epoch 465/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22833148.0000 - val_loss: 205805072.0000\n",
      "Epoch 466/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22627554.0000 - val_loss: 205715968.0000\n",
      "Epoch 467/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22707864.0000 - val_loss: 205629728.0000\n",
      "Epoch 468/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22918272.0000 - val_loss: 205540752.0000\n",
      "Epoch 469/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22947958.0000 - val_loss: 205460272.0000\n",
      "Epoch 470/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22496618.0000 - val_loss: 205370624.0000\n",
      "Epoch 471/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22767842.0000 - val_loss: 205282352.0000\n",
      "Epoch 472/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22603990.0000 - val_loss: 205197552.0000\n",
      "Epoch 473/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22605516.0000 - val_loss: 205108096.0000\n",
      "Epoch 474/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 22652776.0000 - val_loss: 205020160.0000\n",
      "Epoch 475/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22587866.0000 - val_loss: 204936752.0000\n",
      "Epoch 476/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22359412.0000 - val_loss: 204846096.0000\n",
      "Epoch 477/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22583732.0000 - val_loss: 204760304.0000\n",
      "Epoch 478/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22684060.0000 - val_loss: 204674400.0000\n",
      "Epoch 479/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22813298.0000 - val_loss: 204589744.0000\n",
      "Epoch 480/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22578796.0000 - val_loss: 204498768.0000\n",
      "Epoch 481/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22561358.0000 - val_loss: 204416448.0000\n",
      "Epoch 482/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22359964.0000 - val_loss: 204327488.0000\n",
      "Epoch 483/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22495668.0000 - val_loss: 204240960.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 484/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22367582.0000 - val_loss: 204156368.0000\n",
      "Epoch 485/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22487874.0000 - val_loss: 204067440.0000\n",
      "Epoch 486/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22398306.0000 - val_loss: 203982144.0000\n",
      "Epoch 487/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22535116.0000 - val_loss: 203894608.0000\n",
      "Epoch 488/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22379962.0000 - val_loss: 203811696.0000\n",
      "Epoch 489/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 22247806.0000 - val_loss: 203723520.0000\n",
      "Epoch 490/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 22260300.0000 - val_loss: 203635392.0000\n",
      "Epoch 491/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22344994.0000 - val_loss: 203550704.0000\n",
      "Epoch 492/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22394320.0000 - val_loss: 203460704.0000\n",
      "Epoch 493/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 22424766.0000 - val_loss: 203379968.0000\n",
      "Epoch 494/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22413582.0000 - val_loss: 203296480.0000\n",
      "Epoch 495/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22260350.0000 - val_loss: 203212528.0000\n",
      "Epoch 496/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22245248.0000 - val_loss: 203124272.0000\n",
      "Epoch 497/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22491108.0000 - val_loss: 203039808.0000\n",
      "Epoch 498/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22274850.0000 - val_loss: 202957120.0000\n",
      "Epoch 499/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22346534.0000 - val_loss: 202874704.0000\n",
      "Epoch 500/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 22233788.0000 - val_loss: 202786352.0000\n",
      "Epoch 501/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22257376.0000 - val_loss: 202702464.0000\n",
      "Epoch 502/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22177130.0000 - val_loss: 202617216.0000\n",
      "Epoch 503/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22021274.0000 - val_loss: 202528192.0000\n",
      "Epoch 504/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22232164.0000 - val_loss: 202444768.0000\n",
      "Epoch 505/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22177506.0000 - val_loss: 202355008.0000\n",
      "Epoch 506/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22051750.0000 - val_loss: 202269200.0000\n",
      "Epoch 507/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22132074.0000 - val_loss: 202186992.0000\n",
      "Epoch 508/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22057364.0000 - val_loss: 202097664.0000\n",
      "Epoch 509/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 21899910.0000 - val_loss: 202010448.0000\n",
      "Epoch 510/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22009138.0000 - val_loss: 201927040.0000\n",
      "Epoch 511/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22134414.0000 - val_loss: 201841984.0000\n",
      "Epoch 512/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 22105528.0000 - val_loss: 201755520.0000\n",
      "Epoch 513/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21953568.0000 - val_loss: 201672992.0000\n",
      "Epoch 514/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21936142.0000 - val_loss: 201583424.0000\n",
      "Epoch 515/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22020468.0000 - val_loss: 201497632.0000\n",
      "Epoch 516/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 21823610.0000 - val_loss: 201412480.0000\n",
      "Epoch 517/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22047500.0000 - val_loss: 201327472.0000\n",
      "Epoch 518/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 21889538.0000 - val_loss: 201242624.0000\n",
      "Epoch 519/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 22040748.0000 - val_loss: 201159904.0000\n",
      "Epoch 520/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 22035188.0000 - val_loss: 201073376.0000\n",
      "Epoch 521/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 21755716.0000 - val_loss: 200986304.0000\n",
      "Epoch 522/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21677698.0000 - val_loss: 200898944.0000\n",
      "Epoch 523/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 21857938.0000 - val_loss: 200818304.0000\n",
      "Epoch 524/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21804036.0000 - val_loss: 200732128.0000\n",
      "Epoch 525/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 21625904.0000 - val_loss: 200642096.0000\n",
      "Epoch 526/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21729702.0000 - val_loss: 200558816.0000\n",
      "Epoch 527/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21585290.0000 - val_loss: 200468256.0000\n",
      "Epoch 528/1000\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 21517698.0000 - val_loss: 200380944.0000\n",
      "Epoch 529/1000\n",
      "137/137 [==============================] - 2s 18ms/step - loss: 21799910.0000 - val_loss: 200300864.0000\n",
      "Epoch 530/1000\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 21909412.0000 - val_loss: 200215424.0000\n",
      "Epoch 531/1000\n",
      "137/137 [==============================] - 2s 13ms/step - loss: 21912114.0000 - val_loss: 200130128.0000\n",
      "Epoch 532/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21824394.0000 - val_loss: 200050896.0000\n",
      "Epoch 533/1000\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 21721880.0000 - val_loss: 199961792.0000\n",
      "Epoch 534/1000\n",
      "137/137 [==============================] - 2s 11ms/step - loss: 21571012.0000 - val_loss: 199877280.0000\n",
      "Epoch 535/1000\n",
      "137/137 [==============================] - 2s 16ms/step - loss: 21430926.0000 - val_loss: 199789280.0000\n",
      "Epoch 536/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 21883086.0000 - val_loss: 199704736.0000\n",
      "Epoch 537/1000\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 21520412.0000 - val_loss: 199623568.0000\n",
      "Epoch 538/1000\n",
      "137/137 [==============================] - 2s 11ms/step - loss: 21819510.0000 - val_loss: 199539840.0000\n",
      "Epoch 539/1000\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 21556956.0000 - val_loss: 199452208.0000\n",
      "Epoch 540/1000\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 21704036.0000 - val_loss: 199369696.0000\n",
      "Epoch 541/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21355238.0000 - val_loss: 199281248.0000\n",
      "Epoch 542/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21385492.0000 - val_loss: 199194848.0000\n",
      "Epoch 543/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 21253570.0000 - val_loss: 199107680.0000\n",
      "Epoch 544/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21708844.0000 - val_loss: 199026144.0000\n",
      "Epoch 545/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21542730.0000 - val_loss: 198939184.0000\n",
      "Epoch 546/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21573132.0000 - val_loss: 198856960.0000\n",
      "Epoch 547/1000\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 21561584.0000 - val_loss: 198772688.0000\n",
      "Epoch 548/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21524428.0000 - val_loss: 198690736.0000\n",
      "Epoch 549/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21523238.0000 - val_loss: 198604672.0000\n",
      "Epoch 550/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21546254.0000 - val_loss: 198521072.0000\n",
      "Epoch 551/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21454084.0000 - val_loss: 198438176.0000\n",
      "Epoch 552/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21562132.0000 - val_loss: 198352272.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 553/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21503636.0000 - val_loss: 198274288.0000\n",
      "Epoch 554/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21542150.0000 - val_loss: 198185696.0000\n",
      "Epoch 555/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21698310.0000 - val_loss: 198105040.0000\n",
      "Epoch 556/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21318946.0000 - val_loss: 198017344.0000\n",
      "Epoch 557/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21268864.0000 - val_loss: 197934512.0000\n",
      "Epoch 558/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21621258.0000 - val_loss: 197852800.0000\n",
      "Epoch 559/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21540062.0000 - val_loss: 197774800.0000\n",
      "Epoch 560/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21059324.0000 - val_loss: 197681680.0000\n",
      "Epoch 561/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21318100.0000 - val_loss: 197599584.0000\n",
      "Epoch 562/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21249720.0000 - val_loss: 197516000.0000\n",
      "Epoch 563/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 21124292.0000 - val_loss: 197430800.0000\n",
      "Epoch 564/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 21397478.0000 - val_loss: 197344032.0000\n",
      "Epoch 565/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21403804.0000 - val_loss: 197265168.0000\n",
      "Epoch 566/1000\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 21316978.0000 - val_loss: 197180288.0000\n",
      "Epoch 567/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21405106.0000 - val_loss: 197095456.0000\n",
      "Epoch 568/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21128664.0000 - val_loss: 197012560.0000\n",
      "Epoch 569/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21132534.0000 - val_loss: 196930464.0000\n",
      "Epoch 570/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21072088.0000 - val_loss: 196845376.0000\n",
      "Epoch 571/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21082084.0000 - val_loss: 196759968.0000\n",
      "Epoch 572/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20973178.0000 - val_loss: 196674880.0000\n",
      "Epoch 573/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21260772.0000 - val_loss: 196593424.0000\n",
      "Epoch 574/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21367206.0000 - val_loss: 196511040.0000\n",
      "Epoch 575/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20979002.0000 - val_loss: 196425088.0000\n",
      "Epoch 576/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21191336.0000 - val_loss: 196344112.0000\n",
      "Epoch 577/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21067010.0000 - val_loss: 196263296.0000\n",
      "Epoch 578/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21016612.0000 - val_loss: 196182448.0000\n",
      "Epoch 579/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20895262.0000 - val_loss: 196096528.0000\n",
      "Epoch 580/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 21098740.0000 - val_loss: 196015488.0000\n",
      "Epoch 581/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20912752.0000 - val_loss: 195928064.0000\n",
      "Epoch 582/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20999026.0000 - val_loss: 195842800.0000\n",
      "Epoch 583/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21207828.0000 - val_loss: 195762432.0000\n",
      "Epoch 584/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21223204.0000 - val_loss: 195680128.0000\n",
      "Epoch 585/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20985058.0000 - val_loss: 195601024.0000\n",
      "Epoch 586/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21211354.0000 - val_loss: 195519664.0000\n",
      "Epoch 587/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20979322.0000 - val_loss: 195435184.0000\n",
      "Epoch 588/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 21168852.0000 - val_loss: 195355584.0000\n",
      "Epoch 589/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21095108.0000 - val_loss: 195271680.0000\n",
      "Epoch 590/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20973198.0000 - val_loss: 195189568.0000\n",
      "Epoch 591/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20812062.0000 - val_loss: 195108688.0000\n",
      "Epoch 592/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20718674.0000 - val_loss: 195021600.0000\n",
      "Epoch 593/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20676640.0000 - val_loss: 194941328.0000\n",
      "Epoch 594/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20829364.0000 - val_loss: 194855536.0000\n",
      "Epoch 595/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20907170.0000 - val_loss: 194772000.0000\n",
      "Epoch 596/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20845094.0000 - val_loss: 194687328.0000\n",
      "Epoch 597/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20739066.0000 - val_loss: 194603248.0000\n",
      "Epoch 598/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20749274.0000 - val_loss: 194521792.0000\n",
      "Epoch 599/1000\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 20764348.0000 - val_loss: 194440688.0000\n",
      "Epoch 600/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20863024.0000 - val_loss: 211262272.0000\n",
      "Epoch 601/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 24468112.0000 - val_loss: 198873168.0000\n",
      "Epoch 602/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 21218122.0000 - val_loss: 194222192.0000\n",
      "Epoch 603/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20682618.0000 - val_loss: 194141728.0000\n",
      "Epoch 604/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20519442.0000 - val_loss: 194059792.0000\n",
      "Epoch 605/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20812220.0000 - val_loss: 193977968.0000\n",
      "Epoch 606/1000\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 20882030.0000 - val_loss: 193899760.0000\n",
      "Epoch 607/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20870560.0000 - val_loss: 193820704.0000\n",
      "Epoch 608/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 20640060.0000 - val_loss: 193739840.0000\n",
      "Epoch 609/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20716902.0000 - val_loss: 193660336.0000\n",
      "Epoch 610/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20776276.0000 - val_loss: 193580896.0000\n",
      "Epoch 611/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20566674.0000 - val_loss: 193494016.0000\n",
      "Epoch 612/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 20615896.0000 - val_loss: 193413520.0000\n",
      "Epoch 613/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 20824270.0000 - val_loss: 193336848.0000\n",
      "Epoch 614/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20554690.0000 - val_loss: 193246848.0000\n",
      "Epoch 615/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20472672.0000 - val_loss: 193166208.0000\n",
      "Epoch 616/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21320630.0000 - val_loss: 194306416.0000\n",
      "Epoch 617/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20674028.0000 - val_loss: 194131264.0000\n",
      "Epoch 618/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21078620.0000 - val_loss: 194022112.0000\n",
      "Epoch 619/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20740712.0000 - val_loss: 192856928.0000\n",
      "Epoch 620/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 20801116.0000 - val_loss: 192780224.0000\n",
      "Epoch 621/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 20678004.0000 - val_loss: 192702816.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 622/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 20516978.0000 - val_loss: 192619984.0000\n",
      "Epoch 623/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20719102.0000 - val_loss: 192545408.0000\n",
      "Epoch 624/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20564818.0000 - val_loss: 192463888.0000\n",
      "Epoch 625/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20397086.0000 - val_loss: 192385152.0000\n",
      "Epoch 626/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20641726.0000 - val_loss: 192305776.0000\n",
      "Epoch 627/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 20689436.0000 - val_loss: 194833712.0000\n",
      "Epoch 628/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 21161506.0000 - val_loss: 194381312.0000\n",
      "Epoch 629/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20870776.0000 - val_loss: 193510240.0000\n",
      "Epoch 630/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20657274.0000 - val_loss: 193143152.0000\n",
      "Epoch 631/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20666072.0000 - val_loss: 193032960.0000\n",
      "Epoch 632/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20460890.0000 - val_loss: 192846208.0000\n",
      "Epoch 633/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20287146.0000 - val_loss: 191791280.0000\n",
      "Epoch 634/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20240832.0000 - val_loss: 191695120.0000\n",
      "Epoch 635/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20355738.0000 - val_loss: 191614128.0000\n",
      "Epoch 636/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20566514.0000 - val_loss: 191524784.0000\n",
      "Epoch 637/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20397970.0000 - val_loss: 191446560.0000\n",
      "Epoch 638/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20247662.0000 - val_loss: 191364608.0000\n",
      "Epoch 639/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20338980.0000 - val_loss: 191268544.0000\n",
      "Epoch 640/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 20391810.0000 - val_loss: 191202672.0000\n",
      "Epoch 641/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 20359710.0000 - val_loss: 191118368.0000\n",
      "Epoch 642/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 20322160.0000 - val_loss: 191037408.0000\n",
      "Epoch 643/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20147056.0000 - val_loss: 190955520.0000\n",
      "Epoch 644/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 20126774.0000 - val_loss: 190871824.0000\n",
      "Epoch 645/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20245084.0000 - val_loss: 190787440.0000\n",
      "Epoch 646/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19994942.0000 - val_loss: 190704688.0000\n",
      "Epoch 647/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20163488.0000 - val_loss: 190626416.0000\n",
      "Epoch 648/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20025900.0000 - val_loss: 190543056.0000\n",
      "Epoch 649/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20028800.0000 - val_loss: 190456080.0000\n",
      "Epoch 650/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20007998.0000 - val_loss: 190376336.0000\n",
      "Epoch 651/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20366668.0000 - val_loss: 190295888.0000\n",
      "Epoch 652/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 20067964.0000 - val_loss: 190213216.0000\n",
      "Epoch 653/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 20184612.0000 - val_loss: 190129792.0000\n",
      "Epoch 654/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19938860.0000 - val_loss: 190049408.0000\n",
      "Epoch 655/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20161974.0000 - val_loss: 189962880.0000\n",
      "Epoch 656/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20161236.0000 - val_loss: 189887168.0000\n",
      "Epoch 657/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20036108.0000 - val_loss: 189804912.0000\n",
      "Epoch 658/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20043120.0000 - val_loss: 189721504.0000\n",
      "Epoch 659/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19775622.0000 - val_loss: 189641248.0000\n",
      "Epoch 660/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20063202.0000 - val_loss: 189558592.0000\n",
      "Epoch 661/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19935218.0000 - val_loss: 189481648.0000\n",
      "Epoch 662/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19864938.0000 - val_loss: 189398384.0000\n",
      "Epoch 663/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19982188.0000 - val_loss: 189325824.0000\n",
      "Epoch 664/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19561048.0000 - val_loss: 189228576.0000\n",
      "Epoch 665/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19751982.0000 - val_loss: 189149184.0000\n",
      "Epoch 666/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19830110.0000 - val_loss: 189066224.0000\n",
      "Epoch 667/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19886620.0000 - val_loss: 188984352.0000\n",
      "Epoch 668/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19893816.0000 - val_loss: 188907904.0000\n",
      "Epoch 669/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20074180.0000 - val_loss: 188835680.0000\n",
      "Epoch 670/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19772458.0000 - val_loss: 188752080.0000\n",
      "Epoch 671/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20018720.0000 - val_loss: 188665296.0000\n",
      "Epoch 672/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19878346.0000 - val_loss: 188588544.0000\n",
      "Epoch 673/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19945150.0000 - val_loss: 188506656.0000\n",
      "Epoch 674/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19781064.0000 - val_loss: 188434176.0000\n",
      "Epoch 675/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19631980.0000 - val_loss: 188346352.0000\n",
      "Epoch 676/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19769498.0000 - val_loss: 188269440.0000\n",
      "Epoch 677/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19719828.0000 - val_loss: 188194416.0000\n",
      "Epoch 678/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 19670030.0000 - val_loss: 188109392.0000\n",
      "Epoch 679/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 19854216.0000 - val_loss: 188030112.0000\n",
      "Epoch 680/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19675344.0000 - val_loss: 187949152.0000\n",
      "Epoch 681/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19869324.0000 - val_loss: 187875200.0000\n",
      "Epoch 682/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 19567848.0000 - val_loss: 187788224.0000\n",
      "Epoch 683/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 19563644.0000 - val_loss: 187707360.0000\n",
      "Epoch 684/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 19534036.0000 - val_loss: 187627712.0000\n",
      "Epoch 685/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 19589096.0000 - val_loss: 187546096.0000\n",
      "Epoch 686/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 19778286.0000 - val_loss: 187470240.0000\n",
      "Epoch 687/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 19639564.0000 - val_loss: 187385680.0000\n",
      "Epoch 688/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 19666044.0000 - val_loss: 187306512.0000\n",
      "Epoch 689/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19741076.0000 - val_loss: 187231584.0000\n",
      "Epoch 690/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 19766856.0000 - val_loss: 187151200.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 691/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 19490628.0000 - val_loss: 187067968.0000\n",
      "Epoch 692/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19627746.0000 - val_loss: 186990400.0000\n",
      "Epoch 693/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 19481722.0000 - val_loss: 186909760.0000\n",
      "Epoch 694/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19651476.0000 - val_loss: 186830096.0000\n",
      "Epoch 695/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19653162.0000 - val_loss: 186753008.0000\n",
      "Epoch 696/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19602304.0000 - val_loss: 186669408.0000\n",
      "Epoch 697/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19636696.0000 - val_loss: 186591360.0000\n",
      "Epoch 698/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19530720.0000 - val_loss: 186512160.0000\n",
      "Epoch 699/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19515194.0000 - val_loss: 186435280.0000\n",
      "Epoch 700/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19505512.0000 - val_loss: 186358784.0000\n",
      "Epoch 701/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19369626.0000 - val_loss: 186273616.0000\n",
      "Epoch 702/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19407002.0000 - val_loss: 186193088.0000\n",
      "Epoch 703/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20448820.0000 - val_loss: 186133888.0000\n",
      "Epoch 704/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21179392.0000 - val_loss: 186084992.0000\n",
      "Epoch 705/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20827240.0000 - val_loss: 186041584.0000\n",
      "Epoch 706/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21443664.0000 - val_loss: 186002400.0000\n",
      "Epoch 707/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20994542.0000 - val_loss: 185953584.0000\n",
      "Epoch 708/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 21202630.0000 - val_loss: 185910368.0000\n",
      "Epoch 709/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 20607884.0000 - val_loss: 185856832.0000\n",
      "Epoch 710/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19807344.0000 - val_loss: 188179680.0000\n",
      "Epoch 711/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19904446.0000 - val_loss: 185719680.0000\n",
      "Epoch 712/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19279972.0000 - val_loss: 185652752.0000\n",
      "Epoch 713/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19644854.0000 - val_loss: 185577488.0000\n",
      "Epoch 714/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 19790640.0000 - val_loss: 185506944.0000\n",
      "Epoch 715/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19921992.0000 - val_loss: 185434368.0000\n",
      "Epoch 716/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19398412.0000 - val_loss: 185360512.0000\n",
      "Epoch 717/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19267170.0000 - val_loss: 185282304.0000\n",
      "Epoch 718/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 20273848.0000 - val_loss: 187611280.0000\n",
      "Epoch 719/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19760490.0000 - val_loss: 187532144.0000\n",
      "Epoch 720/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 20168714.0000 - val_loss: 187458224.0000\n",
      "Epoch 721/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19720482.0000 - val_loss: 187381072.0000\n",
      "Epoch 722/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19590788.0000 - val_loss: 187301392.0000\n",
      "Epoch 723/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19612946.0000 - val_loss: 187220864.0000\n",
      "Epoch 724/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 19546904.0000 - val_loss: 187143168.0000\n",
      "Epoch 725/1000\n",
      "137/137 [==============================] - 1s 8ms/step - loss: 19655690.0000 - val_loss: 187066768.0000\n",
      "Epoch 726/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19665020.0000 - val_loss: 186986384.0000\n",
      "Epoch 727/1000\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 19222874.0000 - val_loss: 186908816.0000\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(14, 1), return_sequences=True, stateful=False))\n",
    "model.add(LSTM(50, input_shape=(1, 50), return_sequences=True, stateful=False))\n",
    "model.add(LSTM(50, input_shape=(1, 50), return_sequences=False, stateful=False))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "NUM_EPOCHS = 1000\n",
    "\n",
    "result = model.fit(X_train, y_train, batch_size = 1, validation_data = (X_test, y_test), verbose = 1, epochs = NUM_EPOCHS, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 14)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 60)                900       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               6100      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 47,501\n",
      "Trainable params: 47,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 98.8616 - val_loss: 97.1750\n",
      "Epoch 2/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 95.6733 - val_loss: 94.1326\n",
      "Epoch 3/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 92.7907 - val_loss: 91.2281\n",
      "Epoch 4/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 90.0791 - val_loss: 87.9029\n",
      "Epoch 5/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 87.2805 - val_loss: 84.4138\n",
      "Epoch 6/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 83.9243 - val_loss: 80.8806\n",
      "Epoch 7/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 79.8442 - val_loss: 77.0317\n",
      "Epoch 8/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 76.3095 - val_loss: 72.7601\n",
      "Epoch 9/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 71.6313 - val_loss: 68.1809\n",
      "Epoch 10/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 68.1242 - val_loss: 63.1276\n",
      "Epoch 11/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 62.5275 - val_loss: 57.2713\n",
      "Epoch 12/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 56.6481 - val_loss: 50.8228\n",
      "Epoch 13/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 50.4178 - val_loss: 43.6043\n",
      "Epoch 14/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 41.7715 - val_loss: 34.9348\n",
      "Epoch 15/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 32.3238 - val_loss: 24.2985\n",
      "Epoch 16/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 21.8583 - val_loss: 14.2408\n",
      "Epoch 17/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 19.4144 - val_loss: 8.5369\n",
      "Epoch 18/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 18.2723 - val_loss: 8.8451\n",
      "Epoch 19/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 18.8808 - val_loss: 6.4704\n",
      "Epoch 20/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 17.2927 - val_loss: 5.7759\n",
      "Epoch 21/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 18.4732 - val_loss: 6.2170\n",
      "Epoch 22/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 16.2338 - val_loss: 5.6408\n",
      "Epoch 23/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 16.7078 - val_loss: 6.2943\n",
      "Epoch 24/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 17.3191 - val_loss: 7.4634\n",
      "Epoch 25/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 17.7526 - val_loss: 6.3086\n",
      "Epoch 26/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 16.9001 - val_loss: 5.6442\n",
      "Epoch 27/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 17.0665 - val_loss: 5.2355\n",
      "Epoch 28/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 15.9946 - val_loss: 5.3185\n",
      "Epoch 29/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 16.7706 - val_loss: 5.3637\n",
      "Epoch 30/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 16.6313 - val_loss: 6.1777\n",
      "Epoch 31/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 16.4123 - val_loss: 5.5448\n",
      "Epoch 32/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 16.4834 - val_loss: 4.8479\n",
      "Epoch 33/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 15.9133 - val_loss: 5.6182\n",
      "Epoch 34/1500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 17.0168 - val_loss: 4.7226\n",
      "Epoch 35/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 16.6642 - val_loss: 4.9504\n",
      "Epoch 36/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 15.2043 - val_loss: 6.2057\n",
      "Epoch 37/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 15.2917 - val_loss: 6.2916\n",
      "Epoch 38/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 15.5048 - val_loss: 4.5969\n",
      "Epoch 39/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 15.4973 - val_loss: 6.3297\n",
      "Epoch 40/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 15.4291 - val_loss: 7.3540\n",
      "Epoch 41/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 15.0428 - val_loss: 5.3624\n",
      "Epoch 42/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 14.9942 - val_loss: 5.6333\n",
      "Epoch 43/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 15.6020 - val_loss: 4.4393\n",
      "Epoch 44/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 15.6190 - val_loss: 3.7880\n",
      "Epoch 45/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 13.7649 - val_loss: 5.9701\n",
      "Epoch 46/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 15.2623 - val_loss: 5.1041\n",
      "Epoch 47/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 14.1106 - val_loss: 3.4215\n",
      "Epoch 48/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 13.7951 - val_loss: 3.9454\n",
      "Epoch 49/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 13.9230 - val_loss: 3.6681\n",
      "Epoch 50/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 13.9987 - val_loss: 3.5420\n",
      "Epoch 51/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 13.6355 - val_loss: 5.3002\n",
      "Epoch 52/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 14.2154 - val_loss: 4.5969\n",
      "Epoch 53/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 12.6231 - val_loss: 3.2465\n",
      "Epoch 54/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 13.4648 - val_loss: 3.1971\n",
      "Epoch 55/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 11.8121 - val_loss: 2.8009\n",
      "Epoch 56/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 13.1792 - val_loss: 2.6364\n",
      "Epoch 57/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 12.4920 - val_loss: 2.7148\n",
      "Epoch 58/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 13.0738 - val_loss: 2.5610\n",
      "Epoch 59/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 13.0949 - val_loss: 3.9037\n",
      "Epoch 60/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 11.7143 - val_loss: 5.5760\n",
      "Epoch 61/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 11.8862 - val_loss: 2.3175\n",
      "Epoch 62/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 12.3131 - val_loss: 2.9949\n",
      "Epoch 63/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 11.6651 - val_loss: 2.4208\n",
      "Epoch 64/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 12.1986 - val_loss: 2.8014\n",
      "Epoch 65/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 13.0940 - val_loss: 2.2100\n",
      "Epoch 66/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 2ms/step - loss: 11.9361 - val_loss: 1.9974\n",
      "Epoch 67/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 10.2136 - val_loss: 1.9587\n",
      "Epoch 68/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 11.1861 - val_loss: 3.3978\n",
      "Epoch 69/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 11.4564 - val_loss: 1.9203\n",
      "Epoch 70/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 11.1158 - val_loss: 4.9211\n",
      "Epoch 71/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 10.2115 - val_loss: 3.8887\n",
      "Epoch 72/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 11.0200 - val_loss: 1.7488\n",
      "Epoch 73/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 10.9551 - val_loss: 3.1056\n",
      "Epoch 74/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 10.7213 - val_loss: 2.7499\n",
      "Epoch 75/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 10.9274 - val_loss: 4.8676\n",
      "Epoch 76/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.7945 - val_loss: 3.3268\n",
      "Epoch 77/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 10.3048 - val_loss: 2.1249\n",
      "Epoch 78/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 10.6695 - val_loss: 2.1710\n",
      "Epoch 79/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 10.6326 - val_loss: 1.3430\n",
      "Epoch 80/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 10.0101 - val_loss: 1.3668\n",
      "Epoch 81/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.3527 - val_loss: 3.7460\n",
      "Epoch 82/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.1679 - val_loss: 2.3256\n",
      "Epoch 83/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.5486 - val_loss: 3.7773\n",
      "Epoch 84/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 10.6016 - val_loss: 2.7540\n",
      "Epoch 85/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.6326 - val_loss: 2.5734\n",
      "Epoch 86/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.8275 - val_loss: 5.3724\n",
      "Epoch 87/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 10.1590 - val_loss: 2.4883\n",
      "Epoch 88/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.6971 - val_loss: 2.5708\n",
      "Epoch 89/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.5200 - val_loss: 2.2382\n",
      "Epoch 90/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.7270 - val_loss: 3.3409\n",
      "Epoch 91/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.7045 - val_loss: 2.2522\n",
      "Epoch 92/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.8410 - val_loss: 1.2516\n",
      "Epoch 93/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.4290 - val_loss: 2.5336\n",
      "Epoch 94/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.5902 - val_loss: 4.1683\n",
      "Epoch 95/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 10.4390 - val_loss: 1.0260\n",
      "Epoch 96/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.0166 - val_loss: 1.1106\n",
      "Epoch 97/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.4780 - val_loss: 4.1259\n",
      "Epoch 98/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.1916 - val_loss: 3.7453\n",
      "Epoch 99/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.3229 - val_loss: 4.3631\n",
      "Epoch 100/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.6768 - val_loss: 3.6217\n",
      "Epoch 101/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.4014 - val_loss: 3.5136\n",
      "Epoch 102/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.9525 - val_loss: 3.0297\n",
      "Epoch 103/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.0152 - val_loss: 3.1418\n",
      "Epoch 104/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.5590 - val_loss: 2.9971\n",
      "Epoch 105/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.0409 - val_loss: 1.9435\n",
      "Epoch 106/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 10.0159 - val_loss: 1.9992\n",
      "Epoch 107/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.5646 - val_loss: 2.0155\n",
      "Epoch 108/1500\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 9.1193 - val_loss: 3.4590\n",
      "Epoch 109/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.1718 - val_loss: 2.1414\n",
      "Epoch 110/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.9141 - val_loss: 2.6275\n",
      "Epoch 111/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.7755 - val_loss: 2.2649\n",
      "Epoch 112/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.7913 - val_loss: 1.4117\n",
      "Epoch 113/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.2528 - val_loss: 2.1027\n",
      "Epoch 114/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.8616 - val_loss: 3.9146\n",
      "Epoch 115/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.4800 - val_loss: 3.2908\n",
      "Epoch 116/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.7608 - val_loss: 2.0155\n",
      "Epoch 117/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.8412 - val_loss: 4.9269\n",
      "Epoch 118/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.1768 - val_loss: 5.3196\n",
      "Epoch 119/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.2031 - val_loss: 5.2987\n",
      "Epoch 120/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.5494 - val_loss: 2.8328\n",
      "Epoch 121/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.4935 - val_loss: 3.5454\n",
      "Epoch 122/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.8375 - val_loss: 3.7108\n",
      "Epoch 123/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.1385 - val_loss: 1.7611\n",
      "Epoch 124/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.6123 - val_loss: 2.9417\n",
      "Epoch 125/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.7626 - val_loss: 2.6966\n",
      "Epoch 126/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.8492 - val_loss: 3.0957\n",
      "Epoch 127/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.6490 - val_loss: 3.4398\n",
      "Epoch 128/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.9720 - val_loss: 3.4987\n",
      "Epoch 129/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.9041 - val_loss: 3.3316\n",
      "Epoch 130/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.0663 - val_loss: 2.2926\n",
      "Epoch 131/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.6199 - val_loss: 2.1572\n",
      "Epoch 132/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.2438 - val_loss: 4.3754\n",
      "Epoch 133/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.6276 - val_loss: 3.5619\n",
      "Epoch 134/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.2775 - val_loss: 4.1466\n",
      "Epoch 135/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.6236 - val_loss: 4.0805\n",
      "Epoch 136/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.0661 - val_loss: 4.4473\n",
      "Epoch 137/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.8825 - val_loss: 3.8193\n",
      "Epoch 138/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.7761 - val_loss: 5.1096\n",
      "Epoch 139/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.4204 - val_loss: 5.4616\n",
      "Epoch 140/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.8840 - val_loss: 6.1258\n",
      "Epoch 141/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.4109 - val_loss: 2.6113\n",
      "Epoch 142/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.7781 - val_loss: 2.7247\n",
      "Epoch 143/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.7355 - val_loss: 4.4821\n",
      "Epoch 144/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.2017 - val_loss: 4.6368\n",
      "Epoch 145/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.3822 - val_loss: 4.1070\n",
      "Epoch 146/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 2ms/step - loss: 8.6232 - val_loss: 4.5805\n",
      "Epoch 147/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.8304 - val_loss: 4.3126\n",
      "Epoch 148/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.4086 - val_loss: 2.2599\n",
      "Epoch 149/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.7966 - val_loss: 3.1241\n",
      "Epoch 150/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.7854 - val_loss: 5.1480\n",
      "Epoch 151/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.5355 - val_loss: 2.8260\n",
      "Epoch 152/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.8247 - val_loss: 3.4422\n",
      "Epoch 153/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.6543 - val_loss: 5.0118\n",
      "Epoch 154/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.9092 - val_loss: 4.6324\n",
      "Epoch 155/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.6981 - val_loss: 4.1779\n",
      "Epoch 156/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.9596 - val_loss: 3.1046\n",
      "Epoch 157/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.7707 - val_loss: 4.0999\n",
      "Epoch 158/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.8468 - val_loss: 4.8730\n",
      "Epoch 159/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.8614 - val_loss: 6.2676\n",
      "Epoch 160/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.0317 - val_loss: 4.5094\n",
      "Epoch 161/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.6993 - val_loss: 3.0060\n",
      "Epoch 162/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.3018 - val_loss: 6.5809\n",
      "Epoch 163/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.9187 - val_loss: 4.8642\n",
      "Epoch 164/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.2392 - val_loss: 4.4753\n",
      "Epoch 165/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.2002 - val_loss: 4.3934\n",
      "Epoch 166/1500\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 8.2535 - val_loss: 3.5095\n",
      "Epoch 167/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.9652 - val_loss: 5.4961\n",
      "Epoch 168/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.4973 - val_loss: 4.7133\n",
      "Epoch 169/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.3754 - val_loss: 5.1090\n",
      "Epoch 170/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.7039 - val_loss: 4.0758\n",
      "Epoch 171/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.4558 - val_loss: 4.1916\n",
      "Epoch 172/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.7428 - val_loss: 4.7639\n",
      "Epoch 173/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.7849 - val_loss: 4.9598\n",
      "Epoch 174/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.7036 - val_loss: 5.5499\n",
      "Epoch 175/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.1356 - val_loss: 4.7685\n",
      "Epoch 176/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.7964 - val_loss: 4.3058\n",
      "Epoch 177/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.0071 - val_loss: 4.6029\n",
      "Epoch 178/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.3018 - val_loss: 3.5937\n",
      "Epoch 179/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.0330 - val_loss: 4.9633\n",
      "Epoch 180/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.5990 - val_loss: 3.7109\n",
      "Epoch 181/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.2865 - val_loss: 3.2266\n",
      "Epoch 182/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.8015 - val_loss: 5.2106\n",
      "Epoch 183/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.1943 - val_loss: 4.6784\n",
      "Epoch 184/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.7308 - val_loss: 5.6133\n",
      "Epoch 185/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.7792 - val_loss: 4.4625\n",
      "Epoch 186/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.9616 - val_loss: 4.6601\n",
      "Epoch 187/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.9260 - val_loss: 4.5687\n",
      "Epoch 188/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.6678 - val_loss: 3.7923\n",
      "Epoch 189/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.8762 - val_loss: 4.4885\n",
      "Epoch 190/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.8245 - val_loss: 4.8585\n",
      "Epoch 191/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.0108 - val_loss: 3.8003\n",
      "Epoch 192/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.4116 - val_loss: 6.3579\n",
      "Epoch 193/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.6307 - val_loss: 4.3036\n",
      "Epoch 194/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.0224 - val_loss: 5.6686\n",
      "Epoch 195/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.9368 - val_loss: 4.8287\n",
      "Epoch 196/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.4078 - val_loss: 5.5566\n",
      "Epoch 197/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.8452 - val_loss: 6.5234\n",
      "Epoch 198/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.1556 - val_loss: 3.7921\n",
      "Epoch 199/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.9172 - val_loss: 5.1699\n",
      "Epoch 200/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.8991 - val_loss: 5.9745\n",
      "Epoch 201/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.8233 - val_loss: 3.8861\n",
      "Epoch 202/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.0720 - val_loss: 4.9380\n",
      "Epoch 203/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.1219 - val_loss: 4.5169\n",
      "Epoch 204/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.2578 - val_loss: 4.1497\n",
      "Epoch 205/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.5647 - val_loss: 5.2041\n",
      "Epoch 206/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.9775 - val_loss: 4.5600\n",
      "Epoch 207/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.4654 - val_loss: 3.1060\n",
      "Epoch 208/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.2010 - val_loss: 3.2342\n",
      "Epoch 209/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.5649 - val_loss: 4.9688\n",
      "Epoch 210/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.0683 - val_loss: 5.4910\n",
      "Epoch 211/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.1689 - val_loss: 5.3738\n",
      "Epoch 212/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.4272 - val_loss: 5.9403\n",
      "Epoch 213/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.5413 - val_loss: 5.1492\n",
      "Epoch 214/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.9774 - val_loss: 5.9114\n",
      "Epoch 215/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.0556 - val_loss: 6.1040\n",
      "Epoch 216/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.3443 - val_loss: 5.1261\n",
      "Epoch 217/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.0596 - val_loss: 4.4372\n",
      "Epoch 218/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.5490 - val_loss: 5.3543\n",
      "Epoch 219/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.4818 - val_loss: 4.2076\n",
      "Epoch 220/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.8612 - val_loss: 5.3511\n",
      "Epoch 221/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.9495 - val_loss: 5.4019\n",
      "Epoch 222/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.5263 - val_loss: 5.1975\n",
      "Epoch 223/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.4104 - val_loss: 5.9744\n",
      "Epoch 224/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.5857 - val_loss: 3.6346\n",
      "Epoch 225/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.1124 - val_loss: 4.3541\n",
      "Epoch 226/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 2ms/step - loss: 7.7765 - val_loss: 4.9597\n",
      "Epoch 227/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.9157 - val_loss: 6.2906\n",
      "Epoch 228/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.0540 - val_loss: 3.1895\n",
      "Epoch 229/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.0861 - val_loss: 3.2204\n",
      "Epoch 230/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.9797 - val_loss: 3.6580\n",
      "Epoch 231/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.4339 - val_loss: 4.5046\n",
      "Epoch 232/1500\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 8.0619 - val_loss: 2.9609\n",
      "Epoch 233/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.4821 - val_loss: 3.6234\n",
      "Epoch 234/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.0893 - val_loss: 5.9635\n",
      "Epoch 235/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.2265 - val_loss: 4.2685\n",
      "Epoch 236/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.6845 - val_loss: 5.0668\n",
      "Epoch 237/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.0924 - val_loss: 2.5974\n",
      "Epoch 238/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.0879 - val_loss: 5.5444\n",
      "Epoch 239/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.4090 - val_loss: 5.5798\n",
      "Epoch 240/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.7950 - val_loss: 3.9845\n",
      "Epoch 241/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.7886 - val_loss: 5.3720\n",
      "Epoch 242/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.3717 - val_loss: 4.6096\n",
      "Epoch 243/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.8353 - val_loss: 4.7182\n",
      "Epoch 244/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.4293 - val_loss: 5.9961\n",
      "Epoch 245/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.0555 - val_loss: 4.3834\n",
      "Epoch 246/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.5669 - val_loss: 4.2255\n",
      "Epoch 247/1500\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 7.5801 - val_loss: 6.5305\n",
      "Epoch 248/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.3483 - val_loss: 4.0896\n",
      "Epoch 249/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.4853 - val_loss: 6.5569\n",
      "Epoch 250/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.0135 - val_loss: 5.3678\n",
      "Epoch 251/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.8046 - val_loss: 5.3288\n",
      "Epoch 252/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.7890 - val_loss: 5.4800\n",
      "Epoch 253/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.2193 - val_loss: 5.5343\n",
      "Epoch 254/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.1742 - val_loss: 4.7401\n",
      "Epoch 255/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.3942 - val_loss: 5.4183\n",
      "Epoch 256/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.8250 - val_loss: 2.6540\n",
      "Epoch 257/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.9216 - val_loss: 3.9303\n",
      "Epoch 258/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.4624 - val_loss: 4.9192\n",
      "Epoch 259/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.9034 - val_loss: 4.2111\n",
      "Epoch 260/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.2828 - val_loss: 5.2306\n",
      "Epoch 261/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.5775 - val_loss: 4.3110\n",
      "Epoch 262/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.6453 - val_loss: 4.0902\n",
      "Epoch 263/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.7355 - val_loss: 4.8747\n",
      "Epoch 264/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.6086 - val_loss: 5.7268\n",
      "Epoch 265/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.5657 - val_loss: 4.1450\n",
      "Epoch 266/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.7681 - val_loss: 4.3131\n",
      "Epoch 267/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.8121 - val_loss: 4.7903\n",
      "Epoch 268/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.7682 - val_loss: 2.4564\n",
      "Epoch 269/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.9627 - val_loss: 2.5121\n",
      "Epoch 270/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.5786 - val_loss: 2.4642\n",
      "Epoch 271/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.0443 - val_loss: 5.0166\n",
      "Epoch 272/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.6015 - val_loss: 4.2794\n",
      "Epoch 273/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.9309 - val_loss: 4.2109\n",
      "Epoch 274/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.0075 - val_loss: 4.5166\n",
      "Epoch 275/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.8015 - val_loss: 4.5418\n",
      "Epoch 276/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.6620 - val_loss: 4.4003\n",
      "Epoch 277/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.5175 - val_loss: 4.3925\n",
      "Epoch 278/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.6427 - val_loss: 4.0708\n",
      "Epoch 279/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.5405 - val_loss: 3.9560\n",
      "Epoch 280/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.6610 - val_loss: 4.0472\n",
      "Epoch 281/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 9.0546 - val_loss: 4.5795\n",
      "Epoch 282/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.1054 - val_loss: 3.6880\n",
      "Epoch 283/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.1634 - val_loss: 4.8889\n",
      "Epoch 284/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.1860 - val_loss: 3.7968\n",
      "Epoch 285/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.5483 - val_loss: 5.8338\n",
      "Epoch 286/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.0972 - val_loss: 4.1455\n",
      "Epoch 287/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.7402 - val_loss: 2.8538\n",
      "Epoch 288/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.2038 - val_loss: 3.0430\n",
      "Epoch 289/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.6935 - val_loss: 4.6203\n",
      "Epoch 290/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 8.0063 - val_loss: 4.6704\n",
      "Epoch 291/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.4174 - val_loss: 4.2479\n",
      "Epoch 292/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.1329 - val_loss: 3.0949\n",
      "Epoch 293/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.1679 - val_loss: 5.2100\n",
      "Epoch 294/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.4391 - val_loss: 3.9739\n",
      "Epoch 295/1500\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.6192 - val_loss: 3.4528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5ef406af10>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, Input, LSTM\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "#model = Sequential()\n",
    "#model.add()\n",
    "#model.add(LSTM(14, input_shape=(dim), return_sequences=True, stateful=False))\n",
    "#model.add(LSTM(20, input_shape=(dim), return_sequences=False, stateful=False))\n",
    "#model.add(Dense(1, activation='linear'))\n",
    "#model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(14, activation='relu', return_sequences=True, input_shape=(dim,1)))\n",
    "# model.add(LSTM(14, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(1, activation='linear'))\n",
    "\n",
    "#define the learning rate\n",
    "# optimizer = keras.optimizers.Adam(lr=learning_rate)\n",
    "\n",
    "#compile model\n",
    "# model.compile(optimizer=optimizer, loss='mae')\n",
    "\n",
    "input_layer = Input(shape=(dim))\n",
    "dense1 = Dense(60, activation='relu')(input_layer)\n",
    "dense2 = Dense(100, activation='relu')(dense1)\n",
    "dense3 = Dense(100, activation='relu')(dense2)\n",
    "dense4 = Dense(100, activation='relu')(dense3)\n",
    "dense5 = Dense(100, activation='relu')(dense4)\n",
    "dense6 = Dense(100, activation='relu')(dense5)\n",
    "dropout_layer = Dropout(0.2)(dense6)\n",
    "output_layer = Dense(1, activation='linear')(dropout_layer)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200, restore_best_weights=True)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.00001,\n",
    "    decay_steps=100,\n",
    "    decay_rate=0.9)\n",
    "\n",
    "boundaries = [100, 250]\n",
    "values = [0.00001, 0.000001, 0.0000001]\n",
    "learning_rate_fn = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    boundaries, values)\n",
    "\n",
    "# Later, whenever we perform an optimization step, we pass in the step.\n",
    "step = tf.Variable(0, trainable=False)\n",
    "learning_rate = learning_rate_fn(step)\n",
    "\n",
    "#optimizer = tf.keras.optimizers.Adam(lr=0.000001)\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(loss=tf.keras.losses.MeanAbsolutePercentageError(), optimizer=optimizer)\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=5, epochs=1500,\n",
    "          validation_data=(X_test, y_test), shuffle=True, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2141, 2143, 2150, 2153, 2157, 2161, 2162, 2165, 2168, 2174, 2189, 2206, 2230, 2307]\n",
      "[2143, 2150, 2153, 2157, 2161, 2162, 2165, 2168, 2174, 2189, 2206, 2230, 2307, 2257.668]\n",
      "[2150, 2153, 2157, 2161, 2162, 2165, 2168, 2174, 2189, 2206, 2230, 2307, 2257.668, 2268.1975]\n",
      "[2153, 2157, 2161, 2162, 2165, 2168, 2174, 2189, 2206, 2230, 2307, 2257.668, 2268.1975, 2295.2288]\n",
      "[2157, 2161, 2162, 2165, 2168, 2174, 2189, 2206, 2230, 2307, 2257.668, 2268.1975, 2295.2288, 2304.182]\n",
      "[2161, 2162, 2165, 2168, 2174, 2189, 2206, 2230, 2307, 2257.668, 2268.1975, 2295.2288, 2304.182, 2310.4377]\n",
      "[2162, 2165, 2168, 2174, 2189, 2206, 2230, 2307, 2257.668, 2268.1975, 2295.2288, 2304.182, 2310.4377, 2319.8352]\n",
      "[2165, 2168, 2174, 2189, 2206, 2230, 2307, 2257.668, 2268.1975, 2295.2288, 2304.182, 2310.4377, 2319.8352, 2307.6367]\n",
      "[2168, 2174, 2189, 2206, 2230, 2307, 2257.668, 2268.1975, 2295.2288, 2304.182, 2310.4377, 2319.8352, 2307.6367, 2349.418]\n",
      "[2174, 2189, 2206, 2230, 2307, 2257.668, 2268.1975, 2295.2288, 2304.182, 2310.4377, 2319.8352, 2307.6367, 2349.418, 2377.493]\n",
      "[2189, 2206, 2230, 2307, 2257.668, 2268.1975, 2295.2288, 2304.182, 2310.4377, 2319.8352, 2307.6367, 2349.418, 2377.493, 2360.6218]\n",
      "[2206, 2230, 2307, 2257.668, 2268.1975, 2295.2288, 2304.182, 2310.4377, 2319.8352, 2307.6367, 2349.418, 2377.493, 2360.6218, 2391.375]\n",
      "[2230, 2307, 2257.668, 2268.1975, 2295.2288, 2304.182, 2310.4377, 2319.8352, 2307.6367, 2349.418, 2377.493, 2360.6218, 2391.375, 2395.3474]\n",
      "[2307, 2257.668, 2268.1975, 2295.2288, 2304.182, 2310.4377, 2319.8352, 2307.6367, 2349.418, 2377.493, 2360.6218, 2391.375, 2395.3474, 2401.234]\n",
      "2307\n",
      "75\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIoAAAReCAYAAAC4vtvMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXSf9WHn+89jWUY2xjZe8YZlYhtDWAyYnUACCZCk2aZJk6YNUHem0ybpNtN0pj1z72TmtLfLTHPvJJ0m6bQGGpJmawIJzUISEhxsNgNmNZhF8o4t2/FuS5b03D9QcggxYIOk57e8XudwjvjpJ+nzw+YPvc/zfH9FWZYBAAAAgBFVDwAAAACgNghFAAAAACQRigAAAAAYIBQBAAAAkEQoAgAAAGCAUAQAAABAkmRk1QNeyeTJk8v29vaqZwAAAAA0jPvvv39bWZZTXvx4zYei9vb2rFy5suoZAAAAAA2jKIq1h3vcrWcAAAAAJBGKAAAAABggFAEAAACQpA7OKAIAAAAYbIcOHcqGDRty8ODBqqcMqba2tsyaNSutra1H9HyhCAAAAGg6GzZsyHHHHZf29vYURVH1nCFRlmW2b9+eDRs2ZO7cuUf0NW49AwAAAJrOwYMHM2nSpIaNRElSFEUmTZp0VFdNCUUAAABAU2rkSPRTR/sa3XoGAAAAMMy2b9+eK664Ikny3HPPpaWlJVOmTEmS3HvvvRk1alQlu4QiAAAAgGE2adKkrFq1Kkny8Y9/PGPHjs0f/dEf/ezzvb29GTly+LONUAQAAABQA6677rpMnDgxDz74YM4+++wcd9xxPxeQTjvttNx6661pb2/PTTfdlE9+8pPp6enJ+eefn7/7u79LS0vLa94gFAEAAABN7b9987E8vmn3oH7PU2eMy399x+uP+uvWrFmT73//+2lpacnHP/7xwz5n9erV+dKXvpTly5entbU1H/7wh/P5z38+11xzzWtcLRQBAAAA1Iz3ve99r3hl0A9+8IPcf//9Offcc5MkBw4cyNSpUwfl5wtFAAAAQFN7NVf+DJVjjz32Zx+PHDky/f39P/v3n77NfVmWufbaa/MXf/EXg/7zRwz6dwQAAADgNWtvb88DDzyQJHnggQfS0dGRJLniiivy1a9+NVu3bk2S7NixI2vXrh2UnykUAQAAANSgX/7lX86OHTuyaNGifPrTn86CBQuSJKeeemr+7M/+LFdeeWXOOOOMvOUtb8nmzZsH5WcWZVkOyjcaKosXLy5XrlxZ9QwAAACggaxevTqnnHJK1TOGxeFea1EU95dlufjFz3VFEQAAAABJhCIAAAAABghFAAAAACQRigAAAAAYIBQBAAAAkEQoAgAAAGCAUAQAAABQgZaWlixatCinnXZa3ve+92X//v2v+ntdd911+epXv/qaNwlFAAAAABUYPXp0Vq1alUcffTSjRo3KZz7zmZ/7fF9f37BvEooAAAAAKvaGN7whTz/9dH70ox/lTW96Uz74wQ/m9NNPT19fXz72sY/l3HPPzRlnnJHPfvazSZKyLPPRj340p556at7+9rdn69atg7Jj5KB8FwAAAIB69e3/nDz3yOB+zxNOT976l0f01N7e3nz729/O1VdfnSS599578+ijj2bu3Ln5+7//+4wfPz733Xdfuru7c/HFF+fKK6/Mgw8+mCeffDKPPPJItmzZklNPPTVLlix5zbOFIgAAAIAKHDhwIIsWLUry/BVFv/mbv5kVK1bkvPPOy9y5c5Mkt912Wx5++OGfnT+0a9euPPXUU1m2bFl+9Vd/NS0tLZkxY0Yuv/zyQdkkFAEAAADN7Qiv/BlsPz2j6MWOPfbYn31clmU+9alP5aqrrvq553zrW99KURSDvskZRQAAAAA16qqrrsqnP/3pHDp0KEmyZs2a7Nu3L5deemm++MUvpq+vL5s3b84Pf/jDQfl5rigCAAAAqFH/9t/+23R2dubss89OWZaZMmVKbr755rznPe/J7bffntNPPz0LFizIZZddNig/ryjLclC+0VBZvHhxuXLlyqpnAAAAAA1k9erVOeWUU6qeMSwO91qLori/LMvFL36uW88AAAAASCIUAQAAADBAKAIAAAAgiVAEAAAANKlaP7d5MBztaxSKAAAAgKbT1taW7du3N3QsKssy27dvT1tb2xF/zcgh3AMAAABQk2bNmpUNGzakq6ur6ilDqq2tLbNmzTri5wtFAAAAQNNpbW3N3Llzq55Rc9x6BgAAAEASoQgAAACAAUIRAAAAAEmEIgAAAAAGCEUAAAAAJBGKAAAAABggFAEAAACQRCgCAAAAYIBQBAAAAPAK/ustj+avvvNE1TOGnFAEAAAA8DJ6+/rz9Qc3Ztue7qqnDDmhCAAAAOBlPLRhV3Yf7M1lJ0+pesqQE4oAAAAAXsayNV0ZUSSXzJtc9ZQhJxQBAAAAvIxlT3XljFkTMmHMqKqnDDmhCAAAAOAl7Nzfk4fW78ylCxr/trNEKAIAAAB4SXc+vS39ZXLZgsa/7SwRigAAAABe0rI1XTmubWTOnDWh6inDQigCAAAAOIyyLLNszbZcMm9yRrY0R0JpjlcJAAAAcJSe2ro3z+0+mMua5HyiRCgCAAAAOKxla7qSpGkOsk6EIgAAAIDDumNNV+ZNHZsZE0ZXPWXYCEUAAAAAL3Kgpy/3dOzIpfOb52qiRCgCAAAA+AX3dGxPT29/Ll0wueopw0ooAgAAAHiRZWu2ZdTIETl/7qSqpwwroQgAAADgRZY91ZXz507M6FEtVU8ZVkIRAAAAwAts2nkgT2/d23TnEyVCEQAAAMDPWbamK0ly2clCEQAAAEBTW/ZUV04Y15b5U8dWPWXYCUUAAAAAA3r7+vPjp7bl0gWTUxRF1XOGnVAEAAAAMOChDTuz52BvLl3QfLedJUIRAAAAwM/csWZbRhTJJfMmVz2lEkIRAAAAwIBla7pyxqwJmTBmVNVTKiEUAQAAACTZub8nD2/Y2bS3nSVCEQAAAECS5M6nt6W/TC4TigAAAACa27I1XRnXNjJnzhpf9ZTKCEUAAABA0yvLMnes6col8ydnZEvz5pLmfeUAAAAAA9Zs2Zstu7tz6fzmve0sEYoAAAAAsmxNV5I09UHWiVAEAAAAkGVPdWXe1LGZMWF01VMqJRQBAAAATe1AT1/u6djR9LedJUIRAAAA0OTu6dient7+XLpgctVTKicUAQAAAE1t2ZptOWbkiFxw0qSqp1ROKAIAAACa2h1rtua8uRPT1tpS9ZTKCUUAAABA09q480Ce6dqXy5r83c5+SigCAAAAmtayNV1JkkuFoiRCEQAAANDElq3pygnj2jJ/6tiqp9QEoQgAAABoSr19/bnz6W25dMHkFEVR9ZyaIBQBAAAATemhDTuz52Cv285eQCgCAAAAmtIda7ZlRJFcMm9y1VNqhlAEAAAANKU71nTlzNkTMmHMqKqn1AyhCAAAAGg6P9nXk4c37Myl89129kJCEQAAANB07nx6W8oyzid6EaEIAAAAaDrL1nRlXNvInDlrfNVTaopQBAAAADSVsiyz7KmuXDJ/cka2SCMv5L8GAAAA0FTWbNmbLbu7nU90GEIRAAAA0FSWrelK4nyiwxGKAAAAgKZyx5quzJ86NjMmjK56Ss0RigAAAICmcaCnL/d27nA10UsQigAAAICmcXfH9vT09gtFL0EoAgAAAJrGsjVdOWbkiJw/d2LVU2qSUAQAAAA0jWVrunLe3Ilpa22pekpNEooAAACAprBx54E807Uvl7nt7CUJRQAAAEBTWLamK0mcT/QyhCIAAACgKdzxZFemj2/L/Kljq55Ss4QiAAAAoOH19vVn+TPbcun8KSmKouo5NUsoAgAAABreqvU7s+dgr9vOXoFQBAAAADS8ZWu6MqJILpk3ueopNU0oAgAAABreHU9ty5mzJ2T8mNaqp9Q0oQgAAABoaD/Z15OHN+zMpfPddvZKhCIAAACgod359LaUZZxPdASEIgAAAKCh3bGmK+PaRubMWeOrnlLzhCIAAACgYZVlmR8/1ZU3zJ+SkS0yyCvxXwgAAABoWE9u2ZMtu7tz6QLvdnYkhCIAAACgYS1b05XE+URHSigCAAAAGtayNdsyf+rYTB8/uuopdUEoAgAAABrSgZ6+3Nu5w9VER0EoAgAAABrS3R3b09PbLxQdBaEIAAAAaEh3PNmVY0aOyPlzJ1Y9pW4IRQAAAEDDKcsyd6zpyvknTUpba0vVc+qGUAQAAAA0nLue3Z6ObfvyS6dPr3pKXRGKAAAAgIaz9M7OTDx2VN65aEbVU+qKUAQAAAA0lM5t+/KDJ7bk188/0W1nR0koAgAAABrKDSs6M3JEkV+/YE7VU+qOUAQAAAA0jF0HDuXLK9fnHWfMyNRxbVXPqTtCEQAAANAwvrJyffb39OU3Lp5b9ZS69IqhqCiK2UVR/LAoitVFUTxWFMXvDzy+qCiKu4uiWFUUxcqiKM57wdf8SVEUTxdF8WRRFFe94PFziqJ4ZOBznyyKohialwUAAAA0m96+/ly/vDPntU/M6bPGVz2nLh3JFUW9Sf5jWZanJLkgyUeKojg1yV8n+W9lWS5K8n8P/HsGPveBJK9PcnWSvyuK4qcnR306yW8lmT/wz9WD+FoAAACAJvb91VuyceeBLLnE1USv1iuGorIsN5dl+cDAx3uSrE4yM0mZZNzA08Yn2TTw8buSfLEsy+6yLDuSPJ3kvKIopicZV5blXWVZlkn+Kcm7B/XVAAAAAE1r6Z2dmXX86Lzl1GlVT6lbI4/myUVRtCc5K8k9Sf4gyXeLovifeT44XTTwtJlJ7n7Bl20YeOzQwMcvfhwAAADgNXlkw67c27kj/+Xtp6RlhJNuXq0jPsy6KIqxSf4lyR+UZbk7ye8k+cOyLGcn+cMk//jTpx7my8uXefxwP+u3Bs49WtnV1XWkEwEAAIAmdf3yjhw7qiW/cu7sqqfUtSMKRUVRtOb5SPT5siy/NvDwtUl++vFXkvz0MOsNSV74pzIrz9+WtmHg4xc//gvKsvz7siwXl2W5eMqUKUcyEQAAAGhSW3cfzDcf3pT3LZ6dcW2tVc+pa0fyrmdFnr9aaHVZlp94wac2Jbls4OPLkzw18PE3knygKIpjiqKYm+cPrb63LMvNSfYURXHBwPe8Jsktg/Q6AAAAgCZ1091r09tf5rqL2queUveO5Iyii5N8KMkjRVGsGnjsT5P8uyT/qyiKkUkO5vl3M0tZlo8VRfHlJI/n+XdM+0hZln0DX/c7SW5IMjrJtwf+AQAAAHhVDh7qy033rMsVC6elffKxVc+pe68YisqyvDOHP18oSc55ia/58yR/fpjHVyY57WgGAgAAALyUb6zalB37erLkkvaqpzSEIz7MGgAAAKCWlGWZpcs7svCE43LhSZOqntMQhCIAAACgLt31zPY88dyeLLlkbp4/DpnXSigCAAAA6tLS5R2ZdOyovPPMGVVPaRhCEQAAAFB3Orbtyw+e2Jpfu2BO2lpbqp7TMIQiAAAAoO7cuKIzI0cU+fULTqx6SkMRigAAAIC6suvAoXx55fq848wZmXpcW9VzGopQBAAAANSVr6xcn/09fVly8dyqpzQcoQgAAACoG719/bl+eWfOmzsxp80cX/WchiMUAQAAAHXj+6u3ZOPOA64mGiJCEQAAAFA3lt7ZmVnHj85bTp1W9ZSGJBQBAAAAdeGRDbtyb+eOXHdRe1pGFFXPaUhCEQAAAFAXli7vyLGjWvIr586uekrDEooAAACAmrdl98Hc+vCm/Mq5szOurbXqOQ1LKAIAAABq3k13r01vf5nrLmqvekpDE4oAAACAmnbwUF8+f8+6vPmUaZkz6diq5zQ0oQgAAACoabes2pgd+3qy5OK5VU9peEIRAAAAULPKsszSOztzyvRxueCkiVXPaXhCEQAAAFCzVjyzPU9u2ZMlF7enKIqq5zQ8oQgAAACoWUvv7MjksaPyjjNnVD2lKQhFAAAAQE3q2LYvP3hia37t/Dlpa22pek5TEIoAAACAmnTD8o6MahmRX7vgxKqnNA2hCAAAAKg5uw4cylfu35B3nDkjU49rq3pO0xCKAAAAgJrz5fvWZ39PX37j4vaqpzQVoQgAAACoKb19/blhRWfOnzsxp80cX/WcpiIUAQAAADXle49vycadB7LkkrlVT2k6QhEAAABQU5Yu78jsiaPz5lOmVT2l6QhFAAAAQM14eMPO3Nf5k1x30dy0jCiqntN0hCIAAACgZly/vDNjjxmZX1k8q+opTUkoAgAAAGrC1t0Hc+vDm/Lec2bluLbWquc0JaEIAAAAqAk33bMuvf1lrruoveopTUsoAgAAACrX09ufL9yzLm86eWraJx9b9ZymJRQBAAAAlfvWI5uzbW93rnU1UaWEIgAAAKBy16/ozEmTj80b5k2uekpTE4oAAACASq1avzMPrd+Zay9qz4gRRdVzmppQBAAAAFTqxhWdGXvMyPzyObOqntL0hCIAAACgMlv3HMytD2/Ke8+ZlbHHjKx6TtMTigAAAIDK/PM963Oor8w1F86pegoRigAAAICK9PT25/P3rM1lC6bkpCljq55DhCIAAACgIt957Lls3dOd6y5qr3oKA4QiAAAAoBI3LO9I+6QxuWzBlKqnMEAoAgAAAIbdIxt25YF1O3PNhe0ZMaKoeg4DhCIAAABg2N2wojNjRrXkvYtnVT2FFxCKAAAAgGG1bW93vvnQprz3nFkZ19Za9RxeQCgCAAAAhtUX712Xnr7+XHNhe9VTeBGhCAAAABg2h/r6c9Pd6/KG+ZMzb+rYqufwIkIRAAAAMGy++9hzeW73wVx3UXvVUzgMoQgAAAAYNjeu6MyJE8fkjSdPrXoKhyEUAQAAAMPi0Y27cl/nT3LNhXPSMqKoeg6HIRQBAAAAw+LGFZ0Z3dqS9y2eXfUUXoJQBAAAAAy5Hft6cstDm/Jvzp6Z8aNbq57DSxCKAAAAgCH3xfvWpae3P9c6xLqmCUUAAADAkOrt689Nd63NRa+blAXTjqt6Di9DKAIAAACG1Pce35JNuw7mOlcT1TyhCAAAABhSN6zozKzjR+eKU6ZVPYVXIBQBAAAAQ2b15t25p2NHPnTBnLSMKKqewysQigAAAIAhc+OKzrS1jsj7z51d9RSOgFAEAAAADImf7OvJzas25j1nzcyEMaOqnsMREIoAAACAIfGlletz8FB/rnWIdd0QigAAAIBB19df5nN3rc0FJ03MwhPGVT2HIyQUAQAAAIPu+6u3ZOPOA7nO1UR1RSgCAAAABt0NyzszY3xb3nzKtKqncBSEIgAAAGBQPfncntz17PZ86ML2jGyRHuqJPy0AAABgUN14V2eOGTkiHzh3dtVTOEpCEQAAADBodu0/lK8/sDHvWjQjxx87quo5HCWhCAAAABg0X165PgcO9eVah1jXJaEIAAAAGBR9/WX+6e7OnNc+Ma+fMb7qObwKQhEAAAAwKG5/YmvW7zjgaqI6JhQBAAAAg+LGFZ2ZPr4tV75+WtVTeJWEIgAAAOA1e2rLntz59Lb8+gVz0toiN9Qrf3IAAADAa3bjXZ0ZNXJEPnDu7Kqn8BoIRQAAAMBrsvvgoXztgY15xxkzMmnsMVXP4TUQigAAAIDX5CsrN2R/T1+uc4h13ROKAAAAgFetv7/MP93VmXPmHJ/TZ42veg6vkVAEAAAAvGrffvS5rN2+39VEDUIoAgAAAF6V3r7+/M1tT2b+1LF52+nTq57DIBCKAAAAgFflq/dvyLPb9uVjV52clhFF1XMYBEIRAAAAcNQOHurL//f9p3LWiRPyllOnVT2HQSIUAQAAAEftn+7qzHO7D+Y/Xb0wReFqokYhFAEAAABHZffBQ/m7Hz2TSxdMyQUnTap6DoNIKAIAAACOyv9Z9mx27j+UP77q5KqnMMiEIgAAAOCIde3pzj/8uCO/dMb0nDZzfNVzGGRCEQAAAHDE/vb2p9LT15//eKWriRqRUAQAAAAckXXb9+cL967L+8+dnbmTj616DkNAKAIAAACOyP/7/TUZURT5/SvmVz2FISIUAQAAAK/oied25+ZVG3Pdxe2ZNq6t6jkMEaEIAAAAeEX/87tPZuwxI/M7l72u6ikMIaEIAAAAeFkrO3fk+6u35rcve10mjBlV9RyGkFAEAAAAvKSyLPNX33kiU447Jr9xcXvVcxhiQhEAAADwkn70ZFfu6/xJfu+K+RkzamTVcxhiQhEAAABwWP39Zf76u09mzqQx+cC5s6uewzAQigAAAIDD+ubDm7J68+78h7csSGuLhNAM/CkDAAAAv6Cntz9/c9uaLDzhuLzjjBlVz2GYCEUAAADAL/jSyvVZt2N//tPVCzNiRFH1HIaJUAQAAAD8nP09vfnkD57Kee0T88aTp1Q9h2EkFAEAAAA/5/rlnena050/vvrkFIWriZqJUAQAAAD8zM79PfnMHc/kzadMzeL2iVXPYZgJRQAAAMDPfOaOZ7O3uzd/dNXJVU+hAkIRAAAAkCR5btfBXL+8I+9eNDMLTxhX9RwqIBQBAAAASZJP3v5U+ssyf/jmBVVPoSJCEQAAAJCObfvypfvW54PnnZgTJ42peg4VEYoAAACA/M1tT+aYkSPy0cvnVz2FCglFAAAA0OQe3bgrtz68Ob95ydxMOe6YqudQIaEIAAAAmtz/+O6TmTCmNf/u0pOqnkLFhCIAAABoYnc9sz13rOnKh9/4uoxra616DhUTigAAAKBJlWWZv/7uEzlhXFuuubC96jnUAKEIAAAAmtT3Ht+SB9ftzB+8eX7aWluqnkMNEIoAAACgCfX1l/kf330yJ00+Nu89Z1bVc6gRQhEAAAA0oZsf3Jintu7NH111cka2yAM8z98EAAAAaDLdvX35xPfW5PSZ4/PW006oeg41RCgCAACAJnPT3euyceeB/PHVJ6coiqrnUEOEIgAAAGgiuw4cyt/e/lTeMH9y3jB/StVzqDFCEQAAADSRT//omew8cCj/6eqFVU+hBglFAAAA0CQ27jyQpcs78p5FM3PazPFVz6EGCUUAAADQJD5x25okyX+4ckHFS6hVQhEAAAA0gcc37c7XHtyQ37ioPbOOH1P1HGqUUAQAAABN4C+/80TGtbXmw2+cV/UUaphQBAAAAA3ux091Zdmarvzu5fMyfkxr1XOoYUIRAAAANLD+/jJ/8a0nMuv40fnQhXOqnkONE4oAAACggd3y0MY8vnl3PnbVyTlmZEvVc6hxQhEAAAA0qIOH+vI/v7smp80cl3ecMaPqOdQBoQgAAAAa1D/d1ZmNOw/kT996SkaMKKqeQx0QigAAAKAB7dzfk7+9/em88eQpuWje5KrnUCeEIgAAAGhA//uHT2dvd2/+81sXVj2FOiIUAQAAQINZv2N/blyxNu89Z1YWnjCu6jnUEaEIAAAAGszf3PZkRoxI/vAtC6qeQp0RigAAAKCBPLpxV25etSm/ecncTB8/uuo51BmhCAAAABpEWZb5f761OhOPHZV/f9nrqp5DHRKKAAAAoEH8aE1XVjyzPb93+byMa2uteg51SCgCAACABtDXX+Yvv/VE5kwakw+eP6fqOdQpoQgAAAAawL88sCFPbtmTP75qYUaN9Os+r46/OQAAAFDnDvT05RO3rcmZsyfkbaefUPUc6phQBAAAAHVu6fKOPLf7YP70rQtTFEXVc6hjQhEAAADUse17u/PpHz2TN58yLeefNKnqOdQ5oQgAAADq2Kdufzr7e3rzn996ctVTaABCEQAAANSpzm37ctPda/P+c0/MvKnHVT2HBiAUAQAAQJ36H7c9mdaWEfnDN8+vegoNQigCAACAOvTgup/kXx/enH936UmZOq6t6jk0CKEIAAAA6kxZlvmLbz+RyWNH5bcuPanqOTQQoQgAAADqzA9Wb829HTvy+29ekLHHjKx6Dg1EKAIAAIA60tvXn7/8zhM5afKx+cC5s6ueQ4MRigAAAKCOfOX+DXl669788dUL09ri13oGl79RAAAAUCf2dffmE99bk8Vzjs9Vr59W9RwakFAEAAAAdeIfftyRrj3d+ZO3nZKiKKqeQwMSigAAAKAOdO3pzmeXPZO3nnZCzplzfNVzaFBCEQAAANSBz97xTLp7+/Oxq06uegoNTCgCAACAGre3uzdfum993n769Jw0ZWzVc2hgQhEAAADUuK+uXJ893b1ZcsncqqfQ4IQiAAAAqGH9/WWuX9GZs0+ckEWzJ1Q9hwYnFAEAAEANu/2JrVm7fb+riRgWQhEAAADUsKXLOzJjfFuufv0JVU+hCQhFAAAAUKNWb96dFc9szzUXtWdki1/hGXr+lgEAAECNun55R0a3tuQD586uegpNQigCAACAGrRtb3duXrUpv3zOzEwYM6rqOTQJoQgAAABq0BfuWZee3v5cd5FDrBk+QhEAAADUmO7evnzu7rV548lTMm/q2Krn0ESEIgAAAKgxtz60OV17urPkYlcTMbyEIgAAAKghZVlm6fKOzJs6Nm+YP7nqOTQZoQgAAABqyL0dO/LYpt1ZcvHcFEVR9RyajFAEAAAANWTp8o5MGNOa95w1s+opNCGhCAAAAGrEuu37c9vjW/Jr55+Y0aNaqp5DExKKAAAAoEbceFdnWooiH7qgveopNCmhCAAAAGrAnoOH8qX71uftZ0zPCePbqp5DkxKKAAAAoAZ89f4N2dvdm9+4eG7VU2hiQhEAAABUrK+/zA0rOnPOnOOzaPaEqufQxIQiAAAAqNjtT2zN2u37s8TVRFRMKAIAAICKLb2zIzPGt+Wq10+regpNTigCAACACj2+aXfuenZ7rr2oPSNb/JpOtfwNBAAAgApdv7wjo1tb8oFzT6x6CghFAAAAUJVte7tzy6pNee85szJ+TGvVc0AoAgAAgKp8/u516enrz3UXt1c9BZIIRQAAAFCJ7t6+fO7utXnTyVPyuiljq54DSYQiAAAAqMStD23Otr3dWXLJ3KqnwM8IRQAAADDMyrLM0uUdmT91bC6ZN7nqOfAzQhEAAAAMs3s7duSxTbuz5JK5KYqi6jnwM0IRAAAADLOlyzty/JjWvOesmVVPgZ8jFAEAAMAwWrd9f257fEt+7fw5aWttqXoO/ByhCCSiRboAACAASURBVAAAAIbRjXd1pqUo8qEL51Q9BX6BUAQAAADDZM/BQ/nSfevzS2dMz7RxbVXPgV8gFAEAAMAw+er9G7K3uzdLLplb9RQ4LKEIAAAAhkFff5kbVnRm8Zzjc8asCVXPgcMSigAAAGAY/GD1lqzdvt/VRNQ0oQgAAACGwdLlHZk5YXSuPHVa1VPgJQlFAAAAMMQe27Qrdz+7I9deNCcjW/wqTu3ytxMAAACG2PXLOzNmVEvev/jEqqfAyxKKAAAAYAh17enON1ZtynvPmZXxY1qrngMvSygCAACAIfT5e9amp68/113UXvUUeEVCEQAAAAyR7t6+3HT32ly+cGpOmjK26jnwioQiAAAAGCLfWLUp2/b2ZMnFc6ueAkdEKAIAAIAhsOEn+/MX334ir58xLhfPm1T1HDgiQhEAAAAMsoOH+vLbN92fQ739+dSvnpWiKKqeBEdkZNUDAAAAoJGUZZk//fojeXTj7vzjtYudTURdcUURAAAADKIbV3Tmaw9szB+8eX6uOGVa1XPgqAhFAAAAMEjueXZ7/uxfV+fNp0zN710+v+o5cNSEIgAAABgEm3cdyEe+8EBOnDgmn3j/oowY4Vwi6o8zigAAAOA1ev7w6gdyoKcvX/ytCzKurbXqSfCqCEUAAADwGpRlmf96y2N5aP3OfObXz868qcdVPQleNbeeAQAAwGvwhXvX5Usr1+ejb5qXq0+bXvUceE2EIgAAAHiV7l+7Ix//xmN548lT8odvWVD1HHjNhCIAAAB4FbbsPpjfvumBzJgwOv/r/WelxeHVNABnFAEAAMBR6untz4c//0D2HuzN537zvIwf4/BqGoNQBAAAAEfpv9/6WO5f+5P87QfPysITxlU9BwaNW88AAADgKHzpvnW56e51+feXnZRfOmNG1XNgUAlFAAAAcIRWrd+Z/+vmx3LJvMn52JUnVz0HBp1QBAAAAEega093fvtz92fquGPyqV89KyNb/EpN43FGEQAAALyCQ339+cgXHsjOAz35l9+5KMcfO6rqSTAkhCIAAAB4BX/+r6tzb8eO/K8PLMrrZ4yveg4MGdfJAQAAwMv42gMbcsOKziy5eG7etWhm1XNgSAlFAAAA8BIe3bgrf/K1R3LBSRPzJ29bWPUcGHJCEQAAABzGjn09+fefuz+Tjh2Vv/3g2Wl1eDVNwBlFAAAA8CK9ff356BceSNfe7nz1ty/M5LHHVD0JhsUr5tCiKGYXRfHDoihWF0XxWFEUv/+Cz/1uURRPDjz+1y94/E+Konh64HNXveDxc4qieGTgc58siqIY/JcEAAAAr81ffeeJrHhme/783afljFkTqp4Dw+ZIrijqTfIfy7J8oCiK45LcXxTF95JMS/KuJGeUZdldFMXUJCmK4tQkH0jy+iQzkny/KIoFZVn2Jfl0kt9KcneSbyW5Osm3B/tFAQAAwKv1jYc25f/8uCPXXDgn71s8u+o5MKxe8Yqisiw3l2X5wMDHe5KsTjIzye8k+cuyLLsHPrd14EveleSLZVl2l2XZkeTpJOcVRTE9ybiyLO8qy7JM8k9J3j3orwgAAABepe7evvz3bz6eRbMn5L+8/dSq58CwO6qTuIqiaE9yVpJ7kixI8oaiKO4piuKOoijOHXjazCTrX/BlGwYemznw8YsfP9zP+a2iKFYWRbGyq6vraCYCAADAq3brQ5uzbW93/sNbFmTUSIdX03yO+G99URRjk/xLkj8oy3J3nr9t7fgkFyT5WJIvD5w5dLhzh8qXefwXHyzLvy/LcnFZlounTJlypBMBAADgVSvLMkuXd2Te1LF5w/zJVc+BShxRKCqKojXPR6LPl2X5tYGHNyT5Wvm8e5P0J5k88PgLb+KclWTTwOOzDvM4AAAAVO7ejh15bNPuLLl4brz3Es3qSN71rEjyj0lWl2X5iRd86uYklw88Z0GSUUm2JflGkg8URXFMURRzk8xPcm9ZlpuT7CmK4oKB73lNklsG9dUAAADAq7R0eUcmjGnNe8467Ckp0BSO5F3PLk7yoSSPFEWxauCxP02yNMnSoigeTdKT5NqBQ6ofK4riy0kez/PvmPaRgXc8S54/APuGJKPz/LudecczAAAAKrdu+/7c9viW/M5lr8voUS1Vz4HKvGIoKsvyzhz+fKEk+fWX+Jo/T/Lnh3l8ZZLTjmYgAAAADLUb7+pMS1Hkmgvbq54ClXKEOwAAAE1tz8FD+dJ96/P2M6bnhPFtVc+BSglFAAAANLWv3r8he7t78xsXz616ClROKAIAAKBp9fWXuWFFZ86Zc3wWzZ5Q9RyonFAEAABA07r9ia1Zu31/lriaCJIIRQAAADSxpXd2ZMb4tlz1+mlVT4GaIBQBAADQlB7ftDt3Pbs9117UnpEtfj2GRCgCAACgSV2/vCOjW1vygXNPrHoK1AyhCAAAgKazbW93blm1Ke89Z1bGj2mteg7UDKEIAACApvP5u9elp68/113cXvUUqClCEQAAAE2lu7cvn7t7bd508pS8bsrYqudATRGKAAAAaCq3PrQ52/Z2Z8klc6ueAjVHKAIAAKBplGWZf7yzI/Onjs0l8yZXPQdqjlAEAABA07inY0ce37w7Sy6Zm6Ioqp4DNUcoAgAAoGksvbMjx49pzXvOmln1FKhJQhEAAABNYd32/fne6i354Pknpq21peo5UJOEIgAAAJrCDSs601IU+dAF7VVPgZolFAEAANDw9hw8lC+vXJ+3nzE9J4xvq3oO1CyhCAAAgIb3lZUbsre7N0sunlv1FKhpQhEAAAANra+/zA0rOrN4zvE5c/aEqudATROKAAAAaGg/WL0l63bsz5JLXE0Er0QoAgAAoKEtXd6RmRNG58pTp1U9BWqeUAQAAEDDemzTrtz97I5ce9GcjGzxKzC8Ev+XAAAA0LCuX96ZMaNa8v7FJ1Y9BeqCUAQAAEBD6trTnW+s2pT3njMr48e0Vj0H6oJQBAAAQEP6/D1r09PXn+suaq96CtQNoQgAAICG093bl5vuXpvLF07NSVPGVj0H6oZQBAAAQMP55kObs21vT5ZcPLfqKVBXhCIAAAAaSlmWWXpnRxZMG5uL502qeg7UFaEIAACAhnJPx448vnl3llw8N0VRVD0H6opQBAAAQENZemdHjh/TmnefNbPqKVB3hCIAAAAaxrrt+/O91Vvya+fPSVtrS9VzoO4IRQAAADSM61d0pKUo8qEL51Q9BeqSUAQAAEBD2HPwUL6yckN+6YzpmTaureo5UJeEIgAAABrCl1duyN7u3iy5ZG7VU6BuCUUAAADUvb7+Mjes6MjiOcfnjFkTqp4DdUsoAgAAoO59f/WWrN9xwNVE8BoJRQAAANS9pXd2ZOaE0bny1GlVT4G6JhQBAABQ19Zt3597Onbkg+efmJEtfs2F18L/QQAAANS1W1ZtTJK8+6yZFS+B+icUAQAAULfKsszXV23M+XMnZuaE0VXPgbonFAEAAFC3Ht24O8927XM1EQwSoQgAAIC69fUHN2ZUy4i87bTpVU+BhiAUAQAAUJd6+/rzzYc35U0Lp2T8mNaq50BDEIoAAACoSyue2Z6uPd159yK3ncFgEYoAAACoSzev2pjj2kbmTQunVj0FGoZQBAAAQN050NOX7z76XN522vS0tbZUPQcahlAEAABA3fne6i3Z19Pn3c5gkAlFAAAA1J2bH9yY6ePbcv7ciVVPgYYiFAEAAFBXtu/tzrI1XXnnohkZMaKoeg40FKEIAACAuvKvj2xOb3/p3c5gCAhFAAAA1JWbH9yYhSccl1Omj6t6CjQcoQgAAIC6sXb7vjywbmfe5WoiGBJCEQAAAHXjllWbkiTvWjSj4iXQmIQiAAAA6kJZlrl51cacP3diZkwYXfUcaEhCEQAAAHXhkY278mzXvrznLLedwVARigAAAKgLNz+4KaNaRuStp0+vego0LKEIAACAmtfb159vPLQply+cmvGjW6ueAw1LKAIAAKDmrXhme7bt7c67z3KINQwloQgAAICad/ODGzOubWTeePLUqqdAQxOKAAAAqGn7e3rz3ceey9tOn5621paq50BDE4oAAACoad97fEv29fTl3d7tDIacUAQAAEBNu2XVpswY35bz2idWPQUanlAEAABAzdq+tzt3rOnKOxbNyIgRRdVzoOEJRQAAANSsf31kc/r6y7zHbWcwLIQiAAAAatbXH9yYhSccl4UnjKt6CjQFoQgAAICatHb7vjy4bqdDrGEYCUUAAADUpJsf3JSiSN555oyqp0DTEIoAAACoOWVZ5pZVG3P+3ImZMWF01XOgaQhFAAAA1JyHN+zKs9v25d2L3HYGw0koAgAAoObcvGpjRrWMyFtPn171FGgqQhEAAAA1pbevP998aHMuXzg140e3Vj0HmopQBAAAQE1Z/sz2bNvb7d3OoAJCEQAAADXllgc3ZlzbyLxp4ZSqp0DTEYoAAACoGft7evOdx57L28+YnmNGtlQ9B5qOUAQAAEDN+N7jW7K/py/v8m5nUAmhCAAAgJpx84MbM2N8W85rn1j1FGhKQhEAAAA1Yfve7ix7alveuWhmRowoqp4DTUkoAgAAoCbc+vDm9PWXeY93O4PKCEUAAADUhJtXbczCE47LySccV/UUaFpCEQAAAJXr3LYvD67bmXe7mggqJRQBAABQuVtWbUpRJO88c0bVU6CpCUUAAABUqizL3LxqY86fOzEzJoyueg40NaEIAACASj28YVc6tu1ziDXUAKEIAACASn39wY0Z1TIiV582veop0PSEIgAAACrT29efWx/elCtOmZrxo1urngNNTygCAACgMsuf2Z5te3vyrkVuO4NaIBQBAABQmZsf3JhxbSPzpoVTqp4CRCgCAACgIvt7evPdx57L28+YnmNGtlQ9B4hQBAAAQEW+9/iW7O/py7vddgY1QygCAACgEjc/uDEzxrfl3PaJVU8BBghFAAAADLtNOw9k2VPb8s5FMzNiRFH1HGCAUAQAAMCw++wdz6RI8qEL51Q9BXgBoQgAAIBhtXX3wfzzfevzy2fPyswJo6ueA7yAUAQAAMCw+j8/fja9ff358JteV/UU4EWEIgAAAIbN9r3duenudXnXopmZM+nYqucALyIUAQAAMGyWLu/Iwd6+fMTVRFCThCIAAACGxa79h3LjirV522nTM2/qcVXPAQ5DKAIAAGBY3LCiM3u7e/PRy+dVPQV4CUIRAAAAQ27PwUNZurwjbz5lWk6ZPq7qOcBLEIoAAAAYcjfdvS67DhzK77qaCGqaUAQAAMCQ2t/Tm3/48bO5dMGUnDl7QtVzgJchFAEAADCk/vne9dm+rye/52oiqHlCEQAAAEPm4KG+fPaOZ3LBSROzuH1i1XOAVyAUAQAAMGS+cv+GbN3Tnd+7fH7VU4AjIBQBAAAwJHp6+/OZHz2Ts0+ckAtfN6nqOcAREIoAAAAYEjc/uDEbdx7I714xP0VRVD0HOAJCEQAAAIOut68///tHT+f0mePzxgVTqp4DHCGhCAAAgEF368Obs3b7/nz08nmuJoI6IhQBAAAwqPr7y/ztD5/OydOOy1tOmVb1HOAoCEUAAAAMqu889lye3ro3H718XkaMcDUR1BOhCAAAgEFTlmU+dfvTOWnKsXnb6dOrngMcJaEIAACAQfOD1VuzevPufOSN89LiaiKoO0IRAAAAg+L5q4meyuyJo/PORTOqngO8CkIRAAAAg2LZU9vy0IZd+fAb56W1xa+bUI/8nwsAAMBrVpZlPvWDpzJ9fFv+zdn/P3v3HWdVfed//HWmw9B77yBFQOnGrtgSewgaDcbEkrimuJseN8nmt5vdJKZs1NWNmrL23jAWwB5D0UEEGUDq0Ic2wMzAMO38/rigqChl7r3nltfz8eABOXPvOe/JI1wzb7/fz7d71HEkHSGLIkmSJElSk81asY23yir4+sn9KczLjTqOpCNkUSRJkiRJarJbX15KhxaFXDK2Z9RRJDWBRZEkSZIkqUlKyip4Y9lWvnZSP4ryXU0kpTOLIkmSJElSk9z60lLaNs/nsvG9oo4iqYksiiRJkiRJR2zB2h28vGQzV5/Yj+LCvKjjSGoiiyJJkiRJ0hG79eWltCrKY8pxvaOOIikOLIokSZIkSUdk8cadvLCwnCuP70urovyo40iKA4siSZIkSdIR+Z+Xl1NckMtXj+8TdRRJcWJRJEmSJEk6bMs3V/HM/PVMOa4PbZoXRB1HUpxYFEmSJEmSDtttLy+nMC+Hq0/sG3UUSXFkUSRJkiRJOiyrt+7iyXnruGxcbzq0KIw6jqQ4siiSJEmSJB2W219dTm4QcO1J/aKOIinOLIokSZIkSYds/fbdPFqyhslje9CldVHUcSTFmUWRJEmSJOmQ3fHaCsIQvn5y/6ijSEoAiyJJkiRJ0iHZUrWHB+as5uJR3enRtnnUcSQlgEWRJEmSJOmQTFtYzp76Rr5yvCedSZnKokiSJEmSdEiml26kZ7tmDO7SMuookhLEokiSJEmSdFDVe+p5Y/lWzhjShSAIoo4jKUEsiiRJkiRJB/X60s3U1jdyxtDOUUeRlEAWRZIkSZKkg5pWWk7rZvmM7dM26iiSEsiiSJIkSZL0qeobGnlp8SZOG9yJvFx/jJQymX/DJUmSJEmfqqSsgu276tx2JmUBiyJJkiRJ0qeaXlpOQW4OJw3qGHUUSQlmUSRJkiRJ+kRhGDJ9UTnH9W9Pi8K8qONISjCLIkmSJEnSJ1q2qYqyrbvcdiZlCYsiSZIkSdInmlZaDsDEIRZFUjawKJIkSZIkfaLppeWM6NGaLq2Loo4iKQksiiRJkiRJB7SpsoZ5a7a7mkjKIhZFkiRJkqQDenHRJgDnE0lZxKJIkiRJknRAM0rL6dG2GYO7tIw6iqQksSiSJEmSJH3Mrtp6/r5sCxOHdCYIgqjjSEoSiyJJkiRJ0se89t4W9tQ3cqbbzqSsYlEkSZIkSfqYGYvKaVWUx9i+7aKOIimJLIokSZIkSR/S0Bjy0uJNnDq4E/m5/tgoZRP/xkuSJEmSPqSkrIJt1bWediZlIYsiSZIkSdKHzFhUTn5uwMmDOkYdRVKSWRRJkiRJkt4XhiHTS8uZ0K89LYvyo44jKcksiiRJkiRJ71u+uYqVW6o97UzKUhZFkiRJkqT3TS/dBMDpQyyKpGxkUSRJkiRJet/00o0c3b0V3do0izqKpAhYFEmSJEmSANhcuYe312znjCFdoo4iKSIWRZIkSZIkAF5aXE4YwsShnaKOIikiFkWSJEmSJACml5bTvU0zhnZtFXUUSRGxKJIkSZIksbu2gdeXbuGMoZ0JgiDqOJIiYlEkSZIkSeL1pZvZU9/IRE87k7KaRZEkSZIkieml5bQsymN8v3ZRR5EUIYsiSZIkScpyDY0hLy3exKlHdSI/1x8TpWzmJ4AkSZIkZbm3V1ewtbqWiUPddiZlO4siSZIkScpy00vLycsJOOWojlFHkRQxiyJJkiRJynLTF5UzoV97WhXlRx1FUsQsiiRJkiQpiy3fXMWKzdWc4bYzSVgUSZIkSVJWm1FaDuB8IkmARZEkSZIkZbXppeUM7dqK7m2aRR1FUgqwKJIkSZKkLLWlag8lqyvcdibpfRZFkiRJkpSlXlq8iTDEokjS+yyKJEmSJClLTS8tp1vrIoZ1axV1FEkpwqJIkiRJkrLQ7toGXl+6mYlDOxMEQdRxJKUIiyJJkiRJykJvLNtCTV2j284kfYhFkSRJkiRloeml5bQszGN83/ZRR5GUQiyKJEmSJCnLNDSGvLi4nJOP6khBnj8WSvqAnwiSJEmSlGXmrdnOlqpat51J+hiLIkmSJEnKMtNLy8nLCTjlqE5RR5GUYiyKJEmSJCnLzFhUzvh+7WjdLD/qKJJSjEWRJEmSJGWRlVuqWbapiolD3HYm6eMsiiRJkiQpi0wv3QjgfCJJB2RRJEmSJElZZEbpJoZ0bUWPts2jjiIpBVkUSZIkSVKW2FZdy1tl2zhjiEOsJR2YRZEkSZIkZYkXF5XTGMIZQ7tEHUVKPxvegcqNUadIOIsiSZIkScoSMxaV06VVEUd3bxV1FCm97KmEh6bAg5dDGEadJqEsiiRJkiQpC9TUNfDae1uYOLQTQRBEHUdKL9N+AttXw1m/gAz/+2NRJEmSJElZ4I1lW9hd1+C2M+lwLZsBJX+Bz3wTek2IOk3CWRRJkiRJUhaYsaicFoV5TOjXLuooUvrYXQFPfRM6DoZTb4w6TVLkRR1AkiRJkpRYjY0hMxZt4uRBHSnMy406jpQ+nvshVJXDF++H/KKo0ySFK4okSZIkKcPNW7udzZV7OGNo56ijSOlj0VSY/yCc9D3odmzUaZLGokiSJEmSMtyM0nJycwJOOapj1FGk9FC9BabeAF1GwEnfjTpNUrn1TJIkSZIy3PTScsb1aUeb5gVRR5FSXxjCM/8Me3bCRU9Dbn7UiZLKFUWSJEmSlMFWbalm6aYqt51Jh+rdx2DR03Dqj6HzsKjTJJ1FkSRJkiRlsCfnrQOwKJIOxc4N8LfvQI+x8JlvRZ0mEhZFkiRJkpSh6hoauX/2ak4e1JGe7ZpHHUdKbWEIU78F9Xvgwv+FnOw8IdCiSJIkSZIy1PTScjZV7uGK43pHHUVKfW/fA0unwRk/hw4Dok4TGYsiSZIkScpQd89cRY+2zTjlqE5RR5FSW0UZPP8j6HMijL0m6jSRsiiSJEmSpAz0Xnkls1Zs4/LxvcnNCaKOI6WuxkZ46vrYny/4H8jJ7qokL+oAkiRJkqT4u2dmGQV5OVwytmfUUaTU9uadsOp1OO9maOs2zeyuySRJkiQpA1XtqefxuWs5d0RX2hUXRB1HSl1bl8P0n8GAM2DUFVGnSQkWRZIkSZKUYZ6Yu5bq2gamTHB1hPSJGhvgia9DXiGcfwsEbtEEt55JkiRJUkYJw5C7Z5YxvHtrjunZJuo4Uur6xy2wdg5cfBe06hp1mpThiiJJkiRJyiCzVmxj6aYqphzXm8AVEtKBlZfCy7+AIefD8ElRp0kpFkWSJEmSlEHunVVG62b5nD+yW9RRpNTUUAdPfA0KW8G5v3fL2UdYFEmSJElShijfWcMLCzcyeUwPivJzo44jpabXfgMb58dKouIOUadJORZFkiRJkpQh7p+9moYw5EsOsZYObP3b8NpNMOISGHp+1GlSkkWRJEmSJGWAuoZGHpizmpMHdaR3++Ko40ipp64GnrgOWnSCc34VdZqUZVEkSZIkSRlg2sJyNlXuYYqriaQDe+U/YfMiOP9WaNY26jQpy6JIkiRJkjLA3TNX0aNtM045qlPUUaTUs3o2vHEzjL4SBk6MOk1KsyiSJEmSpDS3ZGMls1du40sTepOb4wlO0ofUVsOTX4c2PeHM/4g6TcrLizqAJEmSJKlp7p1VRkFeDpPH9Iw6ipR6ZvwbbFsBX34GCltGnSblHXRFURAEPYMgeDkIgkVBECwMguDbH/n6d4MgCIMg6LDftR8FQbAsCIIlQRCctd/10UEQLNj7tZuDILDqliRJkqQmqKyp4/G5azl3RFfaFRdEHUdKLStegTl3wPjroO+JUadJC4eyoqge+E4YhnODIGgJlARBMD0Mw9IgCHoCZwCr9704CIKhwKXAMKAbMCMIgkFhGDYAtwPXArOAZ4Gzgefi+h1JkiRJUhZ54u11VNc2cMVxfaKOIqWG+lpY8TIsfAIWTYX2A+D0n0adKm0ctCgKw3ADsGHvnyuDIFgEdAdKgd8D3wee2u8tFwAPhmG4B1gZBMEyYFwQBKuAVmEYzgQIguBu4EIsiiRJkiTpiIRhyD0zyxjRozXH9GwTdRwpOvW1sPLVWDm0+Bmo2QFFrWHoBXDCv0BB86gTpo3DmlEUBEEf4FhgdhAE5wPrwjB85yM7yLoTWzG0z9q91+r2/vmj1w/0nGuJrTyiV69ehxNRkiRJkrLGrBXbWLqpipsmjYg6ipR8DXUflEOLnoGa7VDYGgZ/DoZdBP1OgTy3Yx6uQy6KgiBoATwG3EBsO9qNwJkHeukBroWfcv3jF8PwDuAOgDFjxhzwNZIkSZKU7e6ZtYo2zfM5b2S3qKNIydFQD6te+2Bb2e4KKGj5QTnU/1TIK4w6ZVo7pKIoCIJ8YiXRfWEYPh4EwXCgL7BvNVEPYG4QBOOIrRTaf9R+D2D93us9DnBdkiRJknSYNu6o4YWF5Vx1Ql+K8nOjjiMlTkM9lL0BCx+PlUO7tkJBCzjqnL3l0OmQXxR1yoxx0KJo78lkfwIWhWH4O4AwDBcAnfZ7zSpgTBiGW4IgeBq4PwiC3xEbZj0QmBOGYUMQBJVBEEwAZgNXALfE+xuSJEmSpGzwwJzVNIYhl493XIcyUGMDlP1j78qhp6F6M+QXw1Fnx8qhARMhv1nUKTPSoawoOh6YAiwIgmDe3ms/DsPw2QO9OAzDhUEQPExs2HU9cP3eE88ArgP+CjQjNsTaQdaSJEmSdJjqGhp5YM5qTh7Ukd7ti6OOIzVdGMKONbBmTmz10KJnoHoT5DeHQWftLYfOcCh1EhzKqWd/58DzhfZ/TZ+P/OdfAL84wOveAo4+vIiSJEmSpP29sHAjmyr38MvjekcdRToy9bWwcT6smb331xyo3BD7Wn4xDJwYK4cGngkFlqHJdFinnkmSJEmSonfPzDJ6tmvGyYM6HfzFUiqo2gxr53xQCq1/G+prYl9r0wv6nAg9x0HP8dBpKORaV0TF/+YlSZIkKY0s2VjJ7JXb+NE5g8nN+dTNH1I0Ghth8+IPSqE1s2Hb8tjXcvKh2zEw9upYMdRjHLTqGm1efYhFkSRJkiSlkXtmraIgL4cvjOl58BdLybJ6Fqx4NVYKrX0L9uyIXW/eIbZKaNQV0GsCdD3GE8pSnEWRJEmSJKWJypo6npi7jvNGdKNdcUHUcaSYRVPhoS8BQWzb2NEXx8qhnuOgXT8IXPmWTiyKJEmSJClNPPH2JuMrAQAAIABJREFUOqprG7jCIdZKFfV74IUboeMQ+Orz0KxN1InURBZFkiRJkpQGwjDk7plljOjRmpE9/WFcKWLW7bC9DKY8YUmUIXKiDiBJkiRJOriZK7aybFMVUya4mkgpomoTvPYbGHQ29D8t6jSKE4siSZIkSUoD98wso03zfM4b2S3qKFLMy7+A+t1w5n9EnURxZFEkSZIkSSlu444appWWc8mYnhTl50YdR4KNC2Du3TDuWugwMOo0iiOLIkmSJElKcffPWU1jGHL5eLedKQWEIbzwYyhqDSd/P+o0ijOLIkmSJElKYbX1jTwwZzWnDOpIr/bNo44jwZLnYOVrcMqPoVnbqNMoziyKJEmSJCmFTSvdyObKPVxxXJ+oo0hQXwvTboQOR8GYr0SdRgmQF3UASZIkSdInu3tmGT3bNePkQR2jjiLBnDtg2wq4/DHIzY86jRLAFUWSJEmSlKIWb9zJnJXb+NL43uTkBFHHUbar3gKv/hoGTISBE6NOowSxKJIkSZKkFHXPzDIK83KYPKZn1FEkeOW/oLYKzvxF1EmUQBZFkiRJkpSCKmvqeOLtdZw3shttiwuijqNsV14Kb/0Zxl4FnQZHnUYJZFEkSZIkSSno8bnr2FXbwJQJvaOOomwXhvDCj6GwJZzyo6jTKMEsiiRJkiQpxYRhyD2zyhjZozUje7aJOo5SSWND8p+5dBqseBlO/iE0b5f85yupLIokSZIkKcXMXLGVZZuqmHJcn6ijKJW8dhPcNABWz07eMxvq4IUbof0AGHt18p6ryFgUSZIkSVKKeXbBBooLcjl3RNeooyhVbFoEr/wKanbAPRfByteT89w3/wRbl8YGWOc5KysbWBRJkiRJUoqZtWIbY/u2oyg/N+ooSgWNjfDMP0NhC/j669CmJ9w3CZbNSOxzd22LnXTW71QYdFZin6WUYVEkSZIkSSlkc+Uelm2qYkK/9lFHUaqYdy+sngln/gd0HgZX/g06DIQHvgiLn03cc1/5JezZCWf9JwRB4p6jlGJRJEmSJEkpZPbKrQAWRYqp2gzTfgK9j4djLo9dK+4AX54KXYbDw1Pg3cfj/9zNS+DNu2D0ldB5aPzvr5RlUSRJkiRJKWTWiq0UF+RydLdWUUdRKph2I9RWw7n//eFVPc3awpQnocdYeOwqmPdAnJ/7r1BQDKfeGN/7KuVZFEmSJElSCtk3nygv1x/Xst6KV2D+Q3DCP0PHQR//elEr+NJj0OdEePI6eOsv8XnushmwdBqc/P3Y6iVlFT95JEmSJClFOJ9I76uriQ2wbtcPTvzOJ7+uoBguewgGngHP3ACzbm/acxvq4YUboW1fGHdt0+6ltGRRJEmSJEkpwvlEet/rv4VtK+Bzv4P8ok9/bX4zuOQ+GHIePP9DeP13R/7ckr/A5sWxwdl5hUd+H6UtiyJJkiRJShHOJxIAm9+Dv/8eRlwC/U89tPfkFcCkv8LRk+DFn8PL/wlheHjP3V0Re1+fE2Hw5w47tjJDXtQBJEmSJEkxzicSYRjbQlZQDGf+4vDem5sHF98BeUXw6q+gbjec8f8O/Wj7V2+KlUVn/9ehv0cZx6JIkiRJklLAvvlEk0b3iDqKojTvPih7A867GVp0PPz35+TC+bfEtqv942aor4GzfwU5BykftyyDOX+EUVOgy/Ajy66MYFEkSZIkSSnA+USieitM+wn0Og6OnXLk98nJgc/+JrayaOatsbLo3P+OlUifZPpPIK8ZnPaTI3+uMoJFkSRJkiSlAOcTiWn/Cnt2wrm/P/gKoIMJgthA6vxm8NpNsVPULrw9tj3to5a/DEuehYn/Bi06Ne25SnsWRZIkSZKUApxPlOVWvgbv3A8nfgc6DYnPPYMATvvX2Mqil/49trLo83+KDb7ep7EBXrgR2vSG8dfF57lKa34CSZIkSVLE9s0ncttZlqrfA8/8M7TtAyd9L/73P+m7cNZ/wqKn4eEpsdVF+8y9GzYtjA29zi+K/7OVdiyKJEmSJClizifKcn//PWxdBp/7XWyrWCIcd33s/u89Dw9cArXVULMDXvoP6PUZGHpBYp6rtOPWM0mSJEmKmPOJstiWpfD6b+HoSTDg9MQ+a+xVsW1oT38D7p0EnYfCrq1w9n/GtqlJWBRJkiRJUuScT5SlwjC25Sy/WWxrWDIceznkFcLj18Lqf8AxX4Juxybn2UoLFkWSJEmSFKF984kmje4RdRQl2zsPwqrXY6ecteycvOcOnxQrp2bdDqf/JHnPVVqwKJIkSZKkCDmfKEvt2gbTboQe42DUlcl//uDPxX5JH+G6RkmSJEmKkPOJstT0n8SGSZ/335Djj+ZKHf6vUZIkSZIi5HyiLLTq7/D2vXDcN6DzsKjTSB/iJ5EkSZIkRWTffCK3nWWR+j2xAdZtesHJP4g6jfQxziiSJEmSpIg4nygLvXEzbHkPLn8UCppHnUb6GFcUSZIkSVJEZq3YSovCPOcTZYuty+G1m2DYRTDwjKjTSAdkUSRJkiRJEZm1Yhtj+7R1PlE2CMPYlrO8Qjj7l1GnkT6Rn0aSJEmSFAHnE2WZBY/Aylfh9J9Cyy5Rp5E+kUWRJEmSJEXA+URZZNc2eP5H0H0MjPlq1GmkT+Uwa0mSJEmKwL75RMOcT5T5ZvwMdlfAFU9CTm7UaaRP5YoiSZIkSYqA84myRNlMmHs3HPdP0GV41Gmkg/ITSZIkSZKSzPlEWeSlf4dW3eGUH0WdRDokFkWSJEmSlGTOJ8oS5Quh7A0Y/zUoKI46jXRILIokSZIkKcmcT5Ql5twJeUVw7JSok0iHzKJIkiRJkpJs5vKtzifKdDU7YP7DcPQkaN4u6jTSIfNTSZIkSZKSaFNlDcs3V7vtLNPNewDqqmHc1VEnkQ6LRZEkSZIkJdHsFdsA5xNltMZGePNO6D4Guh0bdRrpsFgUSZIkSVISOZ8oC6x8BbYug3HXRp1EOmwWRZIkSZKURLNWOJ8o4825C5p3gGEXRp1EOmx+MkmSJElSkjifKAtsXwPvPQejroC8wqjTSIfNokiSJEmSksT5RFngrT/Hfh/z1WhzSEfIokiSJEmSksT5RBmurgbm/h8c9Vlo0zPqNNIRsSiSJEmSpCRxPlGGK30Sdm2FsVdHnUQ6Yn46SZIkSVISOJ8oC8y5E9oPhH6nRJ1EOmIWRZIkSZKUBM4nynDr5sK6t2DcNRAEUaeRjphFkSRJkiQlgfOJMtybd0F+MYy8NOokUpNYFEmSJElSEjifKIPt2gbvPgYjL4Gi1lGnkZrETyhJkiRJSjDnE2W4t++B+hoYe03USaQmsyiSJEmSpARzPlEGa2yIbTvrfQJ0Hhp1GqnJLIokSZIkKcGcT5TBlk6H7ath3NVRJ5HiwqJIkiRJkhLM+UQZ7M07oWVXGHxu1EmkuPBTSpIkSZISyPlEGWzrclg2A0ZfCbn5UaeR4sKiSJIkSZISyPlEGezNP0FOXqwokjKERZEkSZIkJZDziTJU7S6Ydy8MOR9adok6jRQ3FkWSJEmSlEDOJ8pQCx6Bmh0w7pqok0hx5SeVJEmSJCXIvvlEx/V321lGCcPYEOtOw6DXcVGnkeLKokiSJEmSEsT5RBlqzWzYuCC2migIok4jxZVFkSRJkiQlyKwVW2lZmMfQrs4nyihz7oTC1jBictRJpLizKJIkSZKkBJm1Yitj+7ZzPlEmqdoEpU/BMZdBQXHUaaS489NKkiRJkhJg33yiCf3aRR1F8VTyf9BYB2OvjjqJlBAWRZIkSZKUAM4nykAN9fDWn6H/adBhQNRppISwKJIkSZKkBHA+UQZa8jeoXA9jr4k6iZQwFkWSJEmSlADOJ0qyxsbEP2POndC6Fww6K/HPkiLiJ5YkSZIkxZnziZKovhZm/xF+OwjuvhB2rEvMczYtglWvw9ivQk5uYp4hpQCLIkmSJEmKM+cTJUFjI8x/BG4dA899H9r2hTVz4PbjYMGj8X/em3dBbiEce0X87y2lEIsiSZIkSYoz5xMlUBjC0hlwx0nw+NVQ1Aq+9BhcNQ2+/jp0GASPXQWPXgW7K+LzzJqd8M6DcPTFUGz5p8yWF3UASZIkSco0zidKkLUlMONnsS1gbXrD5/8Ewy6GnL3/PbfvD195Hv7+e3j1l7B6Jlx4G/Q7pWnPnf8Q1FY5xFpZwU8tSZIkSYoj5xMlwJZl8PAVcNdpsVlB59wE33gLhk/6oCTaJzcPTv4eXDUd8pvD3RfA8z+Cut1H9uwwjA2x7jYKeoxu+vcipThXFEmSJElSHM1yPlH87NwQWxk09x7IbwYn/xA+8w0obHnw93YfBV97LbYCadZtsPwluPgO6Dry8DKsfA22LIELbz+y70FKMxZFkiRJkhRHzieKg5od8MYfYOZt0FgPY6+Gk74HLToe3n0KmsNnb4odZ//k9XDn6XDqj+H4bx/6yWVv3gnN2sW2uElZwKJIkiRJkuLI+URNUFcTK2Ze/21sEPXwL8CpN0K7vk2774CJ8E8z4Zkb4MWfw9JpcNH/Qts+n/6+HWth8bOxVUz5RU3LIKUJP7kkSZIkKU427axhhfOJDl9jA7x9H9wyGqb9a2we0Ndeg8/f1fSSaJ/m7eAL/wcX/RHKF8Ltx8Pb98ZmEH2St/4CYSOMuSo+GaQ04IoiSZIkSYqTWSudT3RYwhDeex5m/Bw2L4oVRBfeBv1OTszzggBGXgq9PwNPXAdPXQ9LnoPz/gDFHT782vo9MPf/YNDZ0LZ3YvJIKciiSJIkSZLixPlEh2j3dlj0dGxI9do50K5/bLXP0AtiZU6itekFX54KM2+Fl/4dbjsOLrg1Nston9KnoXozjLs68XmkFGJRJEmSJElx4nyiT1G/B5ZOh/kPwXsvQMOeWEH0ud/BqCsgNz+5eXJy4PhvQf/T4PFr4f7JMOarcOZ/QEFxbFZSu/7Q77Tk5pIiZlEkSZIkSXGwbz7RpWN7Rh0ldTQ2wuqZsXKo9MnYaWbFHWOFzIgvxLaaJWMF0afpcjRc+3JsZdE/boUVr8RORVszG876r1ihJGURiyJJkiRJWStsbICandCsTZPvNXPFVsD5RACUl8KCh2HBo7BjDeQXw5BzYcRk6HsK5KbYj6J5hbGVRAPPgievg6nfhvzmcMxlUSeTki7F/nZKkiRJUvKsuulEllYVcW3dd+Jyv6yeT7RjHbz7KMx/BMoXQJALA06H038Ggz8b286V6vqeCNe9AS/+O7TvH5cCUUo3FkWSJEmSslJ9QyOv7urDl3Jf4AfHd2ZPXtMLnpE92mTXfKKaHbGhz/MfglV/B0LoPgbOuQmGXQQtOkad8PAVtYbP/SbqFFJkLIokSZIkZaUl5ZU8UvsZriz8G9d1fBdGXxl1pPSwbyj1godhyfMfDKU+5Ycw/AuxlTiS0pZFkSRJkqSsVFJWwcKwD3VtB5A//xGLooPZUwmz/xdm/g/srtg7lPorsblDqTCUWlJcWBRJkiRJykolZRV0blVE3jGXwMu/gB1roXWPqGOlntpqmHMnvPEH2L0NBp0DY6+Gfqek3lBqSU2WRZtnJUmSJOkDJWUVjO7dlmD4pNiFBY9GGyjV1NXAzNvgD8fAjJ9B91FwzUtw2YMwcKIlkZSh/JstSZIkKeuU76xhbcVuvnJ8X2jXF3qMhQWPwAk3RB0tevV7YO7d8PpvoXID9D0JTr0Xeo2POpmkJLAokiRJkpR1SsoqABjdu23swvDJ8Nz3oLwUOg+NMFmEGupg3v3w2k2wYw30Og4uvjN2ZLykrOHWM0mSJElZp6SsgsK8HIZ2bRW7MOwiCHJjJ3llm4Z6mPcA3DoGpn4LWnSGKU/AV56zJJKykCuKJEmSJGWdkrIKRvZoQ0He3n933qIj9D8NFjwGp/0UcrLg36k3NsLCx+GVX8LWpdBlBFz2MAw80xPMpCyWBZ9+kiRJkvSBmroGFq7fwah92872GTEZdqyGNbOjCZYsjY1Q+hTc/hl47CrIzYdL7oWvvQaDzrIkkrKcK4okSZIkZZUF63ZQ1xAy5qNF0VGfhfzmse1nvY+LJlwihSG89zy8/AvYuAA6DIJJf4ahF2XHCipJh8SiSJIkSVJWeWtVbJD1x1YUFbaIlUULn4CzfwV5BRGkS5BlL8YKonUl0LYvXPRHGP4FyMmNOpmkFGNtLEmSJCmrlJRV0K9DMe2KD1AEjZgMuytg+YvJD5Yob/4J7r0YqjbD+bfAN96EkZdaEkk6IIsiSZIkSVkjDEPmrq74+GqiffqfBs3bw/wMOf1s+xqY/lPodyp8swRGXRGbSSRJn8CiSJIkSVLWWLV1F9uqaxn9SUVRbj4MuwiWPAd7KpMbLt7CEJ7559jv5/0hs7bSSUoYiyJJkiRJWaOkLDaf6GODrPc3fDLU74ZFzyQpVYLMfxiWTYfTfwpte0edRlKasCiSJEmSlDVKyrbRqiiP/h1bfPKLeo6DNr1gwSPJCxZvVZvh+R9Cj3Ew7pqo00hKIxZFkiRJkrJGSVlsPlFOTvDJLwqC2IlgK16Gqk3JCxdPz/8Aaqtiw6sdWi3pMFgUSZIkScoKO3bX8V55FaN7fcq2s32GT4awEd59PPHB4m3xs/DuY3DS96HT4KjTSEozFkWSJEmSssLbq2PziUb3OYSiqNNg6DIcFqTZ6Wc1O+Bv/wKdhsHx3446jaQ0ZFEkSZIkKSuUlFWQmxMwskebQ3vD8MmwrgS2Lk9ssHia/lOoKocLbvGUM0lHxKJIkiRJUlYoKatgSNeWFBfmHdobhk8CgvQZar3ydSj5Kxx3PXQfHXUaSWnKokiSJElSxqtvaGTemu2HNp9on1bdoM8JsWPmwzBx4eKhdhdM/Ra07Qun/DjqNJLSmEWRJEmSpIy3eGMlu2obGNX7MIoiiJ1+tm05rJ+bmGDx8sp/wbYVcP7NUNA86jSS0phFkSRJkqSMN3fvIOsxfdod3huHXgC5BbDg0QSkipN1c2HmrTDqy9D3pKjTSEpzFkWSJEmSMt5bqyro0qqIbq2LDu+NzdrAwDNjx803NiQmXFM01MHT34QWneGM/xd1GkkZwKJIkiRJUsYrKatgdO+2BEFw+G8eMTl2ktjKV+MfrKne+G8ofxc+97tYqSVJTWRRJEmSJCmjbdxRw7rtuw9/PtE+A8+CwtYwP8VOP9u8BF79NQy7GAZ/Nuo0kjKERZEkSZKkjLZvPtHoIy2K8otg6HmwaCrU7Y5jsiZobICnvgEFxXDOr6NOIymDWBRJkiRJymglZRUU5ecwrFurI7/J8C9AbSUseS5+wZrizbtg7Rw4+5fQomPUaSRlEIsiSZIkSRntrbIKRvRoQ35uE3786XMitOgCC1Jg+9n21TDj5zBgIoy4JOo0kjKMRZEkSZKkjFVT18DCdTuOfNvZPjm5MHwSLJ0Ou7bFJ9yRCEOYegMEAZz7+9jvkhRHFkWSJEmSMtb8tTuobwwZ3auJRRHEtp811kHpU02/15F650FY/iJM/Ddo0yu6HJIylkWRJEmSpIxVUhYbZH3EJ57tr+tI6DAouu1nVZvg+R9Czwkw5qpoMkjKeBZFkiRJkjJWSdk2+nUspl1xQdNvFgQwfDKUvQHb1zT9fofr2e9B3S44/xbI8Uc5SYnhp4skSZKkjBSGISVlFfHZdrbP8Emx3999NH73PBSLnoHSJ+HkH0DHQcl9tqSsYlEkSZIkKSOt3FJNxa66pg+y3l+7vtBjLMxP4vaz3dvhb9+BzsPh+G8n77mSspJFkSRJkqSMtG8+UVyLIohtP9u0EMoXxve+n2T6T6B6E1xwC+TmJ+eZkrKWRZEkSZKkjDR3dQWtivLo37FFfG887CIIcmH+w/G974GseAXm3g2f+SZ0Ozbxz5OU9SyKJEmSJGWkt1ZVMLp3W3JygvjeuEVH6H8aLHgUGhvje+/91e6Cqd+Gdv3glB8l7jmStB+LIkmSJEkZZ8euOpZuqor/trN9RkyGnWthzazE3B/g5V9AxarYKWf5zRL3HEnaj0WRJEmSpIwzd01sPtGoRBVFR30W8psnbvvZ0ukw6zYY81Xoc0JiniFJB2BRJEmSJCnjzC2rIDcnYGSPNol5QGGLWFlU+iTU18bvvjs3wGNXw32ToF1/mPjz+N1bkg6BRZEkSZKkjFNSVsGQri0pLsxL3ENGTIbdFbBsRtPv1VAH/7gVbh0LpU/DyT+Ar78ORa2afm9JOgwJ/NSUJEmSpOSrb2hk3prtTB7TM7EP6n8aNG8PCx6GwZ898vus+jv87buweREMPBPO+VVsgLUkRcCiSJIkSVJGWbyxkl21DYmbT7RPbj4Muwjevhdqdh7+6p/KjTDtJ7GiqXUvuPQBOOocCOJ8SpskHQa3nkmSJEnKKCVlsUHWCTvxbH/DJ0N9DSx+5tDf01APM2+DW8bEZhyd9H24fnZsVZIlkaSIuaJIkiRJUkYpKaugS6siurUuSvzDeo6DNr1ip58dc9nBX1/2j9g2s00LYcBEOOfX0L5/4nNK0iGyKJIkSZKUUUrKKhjduy1BMlbnBAEM/wL8/fdQWQ4tOx/4dZXlMP2nMP9BaN0TLrkPBn/OFUSSUo5bzyRJkiRljA07drNu++7kbDvbZ/hkCBth4eMf/1pDPcz6X7h1TOzrJ34Xrp8DQ861JJKUklxRJEmSJCljzC3bDiRpPtE+nQZDl+Gx7WcTrvvgetlMePa7UP5u7IS0c26CDgOSl0uSjoBFkSRJkqSMUVJWQVF+DkO7HeYJZE01fDJM/wlsXQ6FLWH6z+Cd+6FVD5h8Dww5zxVEktKCRZEkSZKkjFGyuoIRPdqQn5vkKRvDJ8VmEE39NmyYD3W74IR/gZO+CwXFyc0iSU1gUSRJkiQpI+yubWDhuh1cc1K/5D+8VTfocwKseh36nQqfvQk6DEx+DklqIosiSZIkSRlh/trt1DeGjEnmfKL9XXArbFsJ/U5xm5mktGVRJEmSJCkjlKyuAODYXhEVRW37xH5JUhpL8sZdSZIkSUqMuWUV9OtYTLvigqijSFLasiiSJEmSlPbCMKSkrILRUa0mkqQMYVEkSZIkKe2t2FJNxa46Rkc1n0iSMoRFkSRJkqS0V1IWm080po9FkSQ1hUWRJEmSpLQ3t6yC1s3y6dehRdRRJCmtWRRJkiRJSnslZRWM6tWGnByPpZekprAokiRJkpTWtu+qZemmKucTSVIcWBRJkiRJSmtvr94OwOje7SJOIknpz6JIkiRJUlorKasgNydgZM/WUUeRpLRnUSRJkiQprZWUVTC0ayuaF+RFHUWS0p5FkSRJkqS0Vd/QyLw1251PJElxYlEkSZIkKW0t2lDJ7roGRlkUSVJcWBRJkiRJSlslZdsAGGNRJElxYVEkSZIkKW2VrN5O19ZFdGvTLOookpQRLIokSZIkpa25ZRVuO5OkOLIokiRJkpSWNuzYzbrtuxndy6JIkuLFokiSJElSWiopqwDwxDNJiiOLIkmSJElpqaSsgqL8HIZ2axV1FEnKGBZFkiRJktLS3LIKRvZoQ36uP9ZIUrz4iSpJkiQp7eyubWDh+p1uO5OkOLMokiRJkpR23lm7nfrG0KJIkuLMokiSJElS2tk3yHqUJ55JUlxZFEmSJElKO3PLKujfsZi2xQVRR5GkjGJRJEmSJCmthGFIyeoKt51JUgJYFEmSJElKKyu2VLN9V51FkSQlgEWRJEmSpLRSsio2n8iiSJLiz6JIkiRJUlopKaugdbN8+nVoEXUUSco4FkWSJEmS0kZ9QyOzVm5ldO+25OQEUceRpIxjUSRJkiQpbfzhxaWUbd3F50f1iDqKJGUkiyJJkiRJaWHm8q3c+vIyJo3uwedGdI06jiRlJIsiSZIkSSlvW3UtNzz0Nn07FPPz84dFHUeSMpZFkSRJkqSUFoYh33/0HSqq67j50mMpLsyLOpIkZSyLIkmSJEkp7a//WMWMRZv44TmDObp766jjSFJGsyiSJEmSlLIWrt/Bfz27mNMHd+Irx/eJOo4kZTyLIkmSJEkpaVdtPd984G3aFudz0xdGEgRB1JEkKeO5uVeSJElSSvrZUwtZuaWa+64eT7vigqjjSFJWcEWRJEmSpJTz1Lx1PFKylutPGcBn+neIOo4kZQ2LIkmSJEkppWxrNTc+8S6je7flhokDo44jSVnFokiSJElSyqitb+RbD7xNTgB/uPQY8nL9kUWSkskZRZIkSZJSxm+nL+GdtTu47fJR9GjbPOo4kpR1rOclSZIkpYTX3tvMH19dwRfH9eKzw7tGHUeSspJFkSRJkqTIba7cw788/A6DOrfgp+cOjTqOJGUtt55JkiRJilRjY8h3HnmHypo67rt6PM0KcqOOJElZyxVFkiRJkiJ1199X8Np7m/nJuUM5qkvLqONIUlazKJIkSZIUmXfWbOfXzy/hrGGduXx8r6jjSFLWsyiSJEmSFInKmjq++cDbdGpZyK8+P4IgCKKOJElZzxlFkiRJkpIuDEP+9cl3WVuxi4e+dhxtmhdEHUmShCuKJEmSJEXgsbnreGreem6YOIixfdpFHUeStJdFkSRJkqSkWrG5ip8+9S7j+7bj+lMHRB1HkrQfiyJJkiRJSbOnvoFvPvA2BXk5/Pelx5Cb41wiSUolziiSJEmSlDS/fG4xC9fv5M4rxtC1dbOo40iSPsIVRZIkSZKS4sVF5fzljVVc+Zk+nDG0c9RxJEkHYFEkSZIkKeHKd9bwvUfnM6RrK354zuCo40iSPoFFkSRJkqSEqq1v5IYH57G7toFbvngsRfm5UUeSJH0CZxRJkiRJSpiaugb+6b65zFyxld98YSQDOrWIOpIk6VNYFEmSJElKiN21DVx7z1u8vnQL/37h0Uwa3SPqSJKkg7AokiRJkhR31Xvqufr/3mLWyq386vPDuWRsr6gjSZIOwUFnFAVB0DMIgpeDIFgUBMHCIAi+vff6TUEQLA6CYH4QBE8EQdBmv/f8KAiCZUGPPmJ0AAAgAElEQVQQLAmC4Kz9ro8OgmDB3q/dHARBkJhvS5IkSVJUKmvq+PKf5zB75VZ+N3mkJZEkpZFDGWZdD3wnDMMhwATg+iAIhgLTgaPDMBwBvAf8CGDv1y4FhgFnA7cFQbBvWt3twLXAwL2/zo7j9yJJkiQpYjt21fGlP83h7TXbufmLx3LRsW43k6R0ctCiKAzDDWEYzt3750pgEdA9DMNpYRjW733ZLGDfPwEuAB4Mw3BPGIYrgWXAuCAIugKtwjCcGYZhCNwNXBjn70eSJElSRCqqa7nsrlmUrt/BbZeP4twR3aKOJEk6TIeyouh9QRD0AY4FZn/kS18Fntv75+7Amv2+tnbvte57//zR65IkSZLS3JaqPXzxzlks3VTFHVPGcNawLlFHkiQdgUMeZh0EQQvgMeCGMAx37nf9RmLb0+7bd+kAbw8/5fqBnnUtsS1q9OrlfmZJkiQplZXvrOGyO2exbvtu/vzlsZwwsEPUkSRJR+iQVhQFQZBPrCS6LwzDx/e7/mXgXODyvdvJILZSqOd+b+8BrN97vccBrn9MGIZ3hGE4JgzDMR07djzU70WSJElSkq3fvptL/jiTDTtq+OtXxlkSSVKaO5RTzwLgT8CiMAx/t9/1s4EfAOeHYbhrv7c8DVwaBEFhEAR9iQ2tnhOG4QagMgiCCXvveQXwVBy/F0mSJElJtGbbLib/cSZbq2q556pxTOjXPupIkqQmOpStZ8cDU4AFQRDM23vtx8DNQCEwfe8p97PCMPx6GIYLgyB4GCgltiXt+jAMG/a+7zrgr0AzYjONnkOSJElS2lm5pZrL75xFdW0D910znhE92kQdSZIUB8EHO8ZS05gxY8K33nor6hiSJEmS9lq2qZLL7pxNfWPIPVeNY1i31lFHkiQdpiAISsIwHPPR64c8zFqSJEmSFm/cyZfumg0EPHDNBI7q0jLqSJKkODqkYdaSJEmS9O66HVx6xyxycwIe+polkSRlIlcUSZIkSTqoeWu2c8WfZtOyKJ/7rxlP7/bFUUeSJCWARZEkSZKkT/XWqm1c+Zc3aVdcwP3XjKdH2+ZRR5IkJYhbzyRJkiR9opnLt3LFn+fQqWUhD31tgiWRJGU4iyJJkiRJB/Tae5u58i9z6N6mGQ9+bQJdWzeLOpIkKcHceiZJkiTpY6a+s57vPPIO/Tu24N6rxtG+RWHUkSRJSWBRJEmSJOl9YRhy2yvLuemFJYzt05Y7rxhDm+YFUceSJCWJRZEkSZIkAGrrG7nxiQU8UrKWC47pxq8njaAwLzfqWJKkJLIokiRJksSOXXV8/d4SZq7YyrdPH8gNEwcSBEHUsSRJSWZRJEmSJGW51Vt38ZW/zmH1tl38bvJILh7VI+pIkqSIWBRJkiRJWaykbBvX3F1CQ2PIPVeNZ0K/9lFHkiRFyKJIkiRJylL7Tjbr1rqIP185ln4dW0QdSZIUMYsiSZIkKct89GSzP04ZQ7tiTzaTJFkUSZIkSVmltr6RHz+xgEdL1nLhMd34lSebSZL2Y1EkSZIkZYn9Tza7YeJAvn26J5tJkj7MokiSJEnKAqu37uLKv85hzbZd/P6SkVx0rCebSZI+zqJIkiRJynD7TjZrDEPuvWo84z3ZTJL0CSyKJEmSpAz29Dvr+e7ek83+8pVx9O1QHHUkSVIKsyiSJEmSMlAYhvzPy8v4zbT3GNenHX+cMpq2nmwmSToIiyJJkiQpw+x/stlFx3bnl58f7slmkqRDYlEkSZIkZRBPNpMkNYVFkSRJkpQBauoaeHnxJm6atoS123Z7spkk6YhYFEmSJElpqra+kdeXbmbqO+uZXlpOdW0DnVsVcu/V4xnXt13U8SRJaciiSJIkSUoj9Q2NzFyxlanvrOf5dzeys6aeNs3zOf+Ybpw3ohvj+7UnN8etZpKkI2NRJEmSJKW4xsaQN1dtY+r89Ty3YCNbq2tpUZjHmcM6c96Ibhw/oAMFeTlRx5QkZQCLIkmSJCkFhWHIvDXbmfrOBp5dsIGNO2soys/h9CGxcuiUozpSlO9JZpKk+LIokiRJklJEGIaUbtjJM/M3MPWd9ayt2E1Bbg4nH9WRH48cwumDO1Fc6P+FlyQljv+UkSRJkiK2bFMlU9/ZwNT561mxuZrcnIATBnTghomDOGNoZ1o3y486oiQpS1gUSZIkSUmyY3cdS8srWVJeydLyKpZsrOS98kq2VtcSBDChb3uuPqEfZx/dhXbFBVHHlSRlIYsiSZIkKc521zawbFMVS8pjRdC+QmjDjpr3X1NckMvAzi2ZOKQzR3dvxVnDutCpVVGEqSVJsiiSJEmSjlhtfSMrt1THCqGNle8XQ6u37SIMY68pyMthQMcWTOjXnkGdW3JUlxYM6tySbq2bkeMx9pKkFGNRJEmSJB1EQ2PI6m273l8ZFNs6VsmKzdXUN8YaodycgL4dijm6W2suPrYHgzq3YFCXlvRu15y8XI+ulySlB4siSZIkaa8wDFm/o+ZDq4Pe2ztPaE994/uv69muGYM6xbaNHdWlJYM6t6Rfx2IK8zyuXpKU3iyKJEmSlHXCMGRLVe37RdAHc4SqqNpT//7rOrcqZFDnlkyZ0JtBXVpyVOeWDOjUwiPqJUkZy3/CSZIkKSOEYUh1bQNVNfVU1tSxs6aeqj2xP8eu1bO2YtfelUJVbKv+/+3dd3yfd33v/fclyRq2ZMuO95LteCTOcBKbJCQkJCkjhJkUKFBmWW2h0MFdRk/b056bQ9u7QA89d0daWmjLKBBKGQdKQjAOpcTY2ct24j0lx5ItD9mWdJ0/9EswEAcnsf3TeD4fDz8kXZLCx3DFiV58ru/vyOPfO370qCyc0pIbLppROUeoJQsnt2TcaC9LD8DIIhQBADAotXf35I5NXdm1ryfdPUfTfXgg9nT39GZ/z9GBt5Vr+3qO5sDh3lSOCzqu5oa6LJjSnBcsnvLjIDSlJROb61MUDpYGAKEIAICq6+svs3ZXd1Zt6swdmzqzatOebNlz6Ce+pr6uJi0NdWlprEtzY11aGkZl9oTRaW6sy9jGUQPXG+rS0jhq4PONdRnbWJfmhlHHfE+dIAQAT0IoAgDgtNt/uDd3bu7M6k0Dv+7a3JXuytlAE5sbsqxtfN707Dm5qG18Zk8YnZbGOgdFA8BpIBQBAHBKlWWZrZ2HHo9CqzZ1Zs3Ofekvk6JIFk1pycsumJ5lc8Zn6ewJmTWhydYPAFSJUAQAwEl1pLc/D+zYl1Ub9+SOzZ1ZtbEz7d2HkyRj6mtz4ezxefc1C7KsbXwumN2asY0OjAaAwUIoAgDgGek8cGQgCFU2hu7e0pXDvf1JkhmtTXn2mWdkadv4LG0bn0VTWlJXW1PliQGA4xGKAAA4YWVZ5pGOA48fOL16U2ce6TiQJKmrKXLO9LF53SWzs6xtQpa2jc/UcY1VnhgAeCqEIgAAjqvnaF/u3tKV1Zs7s3pjZ1Zv7kzXwaNJktbRo7J09vjccNHMLGsbn/Nntqap3oHTADCUCUUAADyufV/P44+QrdrUmfu37U1vf5kkmTdpTF6weErlMbIJmTdxTGpqHDoNAMOJUAQAMAKVZZltXYeydld31uzcn4d27svqTZ3Z2nkoSdJQV5Mls1rz9ivnZVnb+Fw4e3wmjKmv8tQAwKkmFAEADGNlWaZj/+Gs3bk/a3Z1Z+3O7qzZ1Z2H2/dn/+Hex79u+rjGXDC7NW++bE6WzZmQxdPGpr7OodMAMNIIRQAAw0TXwSNZu+sng9C6Xd3prJwplCQTm+uzYHJLXrl0ZhZOacmiqc2ZP7kl45q8RD0AIBQBAAxJew4cyS0P7sqand2Vx8e60959+PHPtzTUZeHUllx77rQsmtKchVNbsnBKSyY2N1RxagBgsBOKAACGiLIs88P1e/K5lZvzrft25khffxpH1WTB5JZcsWBSFk1tzsIpA0Fo2rjGFIWDpgGAp0YoAgAY5PYcOJKbVm/N51ZuzvrdBzK2sS6vu2R2XrVsZs6aOja1XnkMADhJhCIAgEHose2hz67cnP+obA8taxufd109Py8+f1oaR9VWe0QAYBgSigAABpHjbQ+99uLZWTS1pdrjAQDDnFAEAFBlx9seevc183PdebaHAIDTRygCAKiSPQeO5Eurt+TzK7f8xPbQ6y6ZnYVTbA8BAKefUAQAcBqVZZn/Wv9oPrdyi+0hAGDQEYoAAE6B/Yd7s6PrULbv7Rl4W3n/jk2dtocAgEFLKAIAeIoO9/Zl596ebO/qyY69h7Jjb0+2dR3Kjq6B97d3Hcq+nt6f+J6iSCa3NOTMSc22hwCAQUsoAgA4jo7uw1mxtiP3bd+b7Y9HoJ7s3n/4Z752/OhRmTauKTPHN+XiuRMybVxTprc2Pv52ytjGjKqtqcLvAgDgxAlFAAAVff1l7trSmeVrOrJ8TUfu3bY3STK6vjbTW5sybVxjFk8bm2njmjKttTHTj4lBTfW2gwCAoU8oAgBGtMe2hpav7ciKtR3Ze+hoaorkwtnj874XLMxViyZn8bSxqakpqj0qAMApJxQBACPK8baGJjY35HlnT8lViybligUT0zq6vsqTAgCcfkIRADDsHW9r6CJbQwAAP0EoAgCGnSO9/bl3W5etIQCAp0goAgAGjf7+MgeO9Gb/4d509zz262i6ex67djT7e3qz75iPf/y5H3/94d7+JLE1BADwFAlFAEBVtXf35IurtuaLq7Zk056DKcsn//qiSJob6tLSUJeWxlFpbqzLhDH1aTtjTJob6jK2sS7NDXWZO2lMrpg/KeNGjzo9vxEAgGFAKAIATrv+/jK3Pbw7n7t9c255cFd6+8tcduYZeemS6WlprASghrrK+wMft1QC0Jj6OltBAACniFAEAJw27ft68sXVW/O5lZuztfNQJoypz1ufMze/9KxZmTepudrjAQCMeEIRAHBKHW976P3XnpUXnDMlDXW11R4RAIAKoQgAOCVsDwEADD1CEQBw0jy2PfTZ2zfllgfb02d7CABgSBGKAIBnbNe+nnxx1ZZ8/kdbHt8eepvtIQCAIUcoAgCelv7+MivWdeRzKzfbHgIAGCaEIgDgKXlse+hzK7dkW5ftIQCA4UQoAgB+ruNuD73orLzQ9hAAwLAhFAEAx3W87aHXXDw7cyeOqfZ4AACcZEIRAPAT+vrL3PYE20MfvO6sPH+x7SEAgOFMKAIAkvzs9tAZY+rztivm5jXPsj0EADBSCEUAMII9tj302ds35zsPDWwPXT7f9hAAwEglFAHACGR7CACAJyIUAcAI0d7dk++t6ci3H9iVW4/ZHvrQdWfn+YunpL6uptojAgBQZUIRAAxTvX39uXNLV5avac/yNR25f/u+JMmUsQ152xVz89pnzc4c20MAABxDKAKAYaR9X0+Wr+3I99Z05LZ1HdnX05vamiJL28bnd69dlKsWTs7Z01pSFEW1RwUAYBASigBgCOvt688dm3+8NfTAjoGtocktDbn23Km5atHkXD5/YsY1jarypAAADAVCEQAMMcduDa1Y15FuW0MAAJwkQhEADHJlWWbVps5896Gf3BqaMrYhLzp3aq5eNDmXL5iYsY22hgAAeGaEIgAYpMqyzHfXtOdjN6/Nfdv22RoCAOCUE4oAYJApyzL/+fCj+ejNa3Ln5q7MmtCUP/vF83PteVNtDQEAcEoJRQAwiKzcsCcf/faa3L5hT6aNa8xHbjgvr1w6M6Nqa6o9GgAAI4BQBACDwF1buvLRb6/Jbet2Z1JLQ/77SxfnNRfPTuOo2mqPBgDACCIUAUAV3b99bz5+89rc8mB7Joypz4euOytvuHROmuoFIgAATj+hCACqYN2u7vzFLevyjXt3ZGxjXd73goV58+Vz09zgH80AAFSPfxsFgNNo4+4D+V/fWZev3LUto0fV5j3XzM9br5iXcU0OqQYAoPqEIgA4DbZ2HsxffufhfOmOrRlVW+QdV87LO688MxPG1Fd7NAAAeJxQBACn0K59Pfnftz6cz/9oc4oUecOlbfn1q8/M5JbGao8GAAA/QygCgJOo52hfduztyfauQ7n1ofb8yw83pa+/zKufNSvvvnp+prc2VXtEAAA4LqEIAE5Qb19/dnUfzo6uQ9nWdSg79vZkR9ehbK+EoR17e7LnwJHHv76mSG64aGbec82CzD5jdBUnBwCAEyMUAUDFoSN9Wdfene1dj4WfgQi0o+tQtnf1pL27J/3lT35PS2Ndpo9ryrTWxpw/szUzWhszrfLxmZOaM2WsR8wAABg6hCIARqyyLLNh94EsX9OR765pz+0b9uRIb//jn2+oq8n01qZMG9eYy+dPzPTWxsc/fuxtS6NXKwMAYPgQigAYUQ4d6ct/rd+d5Ws6snxNRzbvOZgkmTdpTF5/SVsunjshM8cPRKAJY+pTFEWVJwYAgNNHKAJgWDve1lDTqNpcduYZefsVc3PVosmZNcEZQgAAIBQBMOwcb2vozElj8oZL23LVokl51pwJaRxVW+VJAQBgcBGKABjybA0BAMDJIRQBMGTt3NuTT/1gY/7PvTtsDQEAwEkgFAEw5KzZ2Z0bV6zPV+/elr7+Mlctmpy3XzkvVy2cZGsIAACeAaEIgCGhLMv81/pHc+OK9Vm+piNNo2rzy5e05a3PmSsOAQDASSIUATCo9fb155v37cyNK9bn3m17M7G5Pu97wcK8/tK2tI6ur/Z4AAAwrAhFAAxKB4/05l9/tCWf/P6GbO08lHkTx+QjN5yX6y+c4dwhAAA4RYQiAAaVju7D+fQPNuaff7gpew8dzbK28fmDlyzO886ekpqaotrjAQDAsCYUATAoPNKxP39/2/rcdMe2HO3rzwsWT8k7rjwzS9vGV3s0AAAYMYQiAKpq1cY9+dsV63PLg7syqrYmr1w6M297ztzMm9Rc7dEAAGDEEYoAOO36+svc/MCu3LjikdyxuSuto0flN66enzdeNicTmxuqPR4AAIxYQhEAp8WBw735wSOPZvma9ixf05FtXYcya0JT/uhl5+RVy2ZmdL1/JAEAQLX5t3IATomyLPNIx/4sX9OR5Ws6snLDnhzp68/o+tpcPn9iPnjdWbn2nKmpq62p9qgAAECFUATASfNEW0NJsmByc950WVuuXjQ5y+ZMSH2dOAQAAIORUATA01aWZR5ur2wNrW3PjzZ05khff8bU1+ay+RPz61efmasWTc6M1qZqjwoAAJwAoQiAp+R4W0MLpzTnzZfPyVULJ9kaAgCAIUooAuBJPdnW0OXzJ+ZdV8/PcxdNsjUEAADDgFAEwM84cLg3//nw7ixf25Hv2RoCAIARQygCwNYQAACQRCgCGLF+7tbQoklZ1mZrCAAARhKhCGCEsDUEAAD8PEIRwDBmawgAAHgqhCKAYeSnt4ZWbtiTo32lrSEAAOCECEUAQ9yTbQ295fK5toYAAIATJhQBDDFlWWZd+/4sX9Oe5Ws68qONtoYAAICTQygCGAKOtzW0aEpLfuXyuXmurSEAAOAkEIoABqET2Rq6atGkTLc1BAAAnERCEcAgUJZltnUdyupNnbl9wx5bQwAAQFUIRQBVcLSvP/dv35fVmzqzetOerN7UmV37DidJmhvqctmZZ+Td18zPcxfaGgIAAE4foQjgNOg8cCR3bO7M6k2dWbWpM/ds7UrP0f4kyYzWplw674wsbRufpW3js2hKS+pqbQ0BAACnn1AEcJKVZZlHOg7kjk2PhaE9eaTjQJKkrqbIOdPH5nUXtz0ehqaOa6zyxAAAAAOEIoBnqLevf+ARss2dWb2xM3ds7kznwaNJktbRo7J09vjccNHMLG0bnyUzW9NUX1vliQEAAJ6YUATwNPX1l/n6PdvzF7esy4bdAxtD8yaNyfMXT6lsC03IvIljUlNTVHlSAACAEyMUATxF/f1l/uP+nfnYzWuzrn1/zprakk+89sI8Z/7ETBhTX+3xAAAAnjahCOAElWWZWx9qz8duXpv7t+/LvElj8r9fd2GuO3earSEAAGBYEIoAfo6yLPP9h3fno99em7u2dGX2hNH56KuW5OUXTPfqZAAAwLAiFAE8idvXP5qP3rw2KzfsyfRxjfnIDefllUtnZpRABAAADENCEcATuHNzZz5289rctm53JrU05I9edk5ec/GsNNR5xTIAAGD4EooAjnHftr35+M1r852H2jNhTH1+77qz8/pL27ykPQAAMCIIRQBJ1u3qzsdvWZv/c+/OjG2sy/tesDBvvnxumhv8MQkAAIwcfgICRrQNuw/kf92yNv9+9/aMHlWb91wzP2+9Yl7GNY2q9mgAAACnnVAEjEgPt3fnxhXrc9Md2zKqtsg7rpyXd155ZiaMqa/2aAAAAFUjFAEjxuZHD+Zr92zP1+/ZkQd37Et9bU3e+Oy2/NpVZ2ZyS2O1xwMAAKg6oQgY1nbsPZRv3LMjX7tnR+7e0pUkuWh2a/7gJYvzkvOnZfJYgQgAAOAxQhEw7OzefzjfvHdHvnb3jqzcuCdJcu6MsfnAi87Ki8+bllkTRld5QgAAgMFJKAKGhb0Hj+Zb9w/EoR88sjv9ZbJgcnN++/kL85Lzp2XepOZqjwgAADDoCUXAkLX/cG9ueWBXvnb39qxY15GjfWXazhidX79qfl66ZHoWTW2p9ogAAABDilAEDCmHjvTlu2va87W7t+fWh9pzuLc/08c15i2Xz81Lz5+ec2eMTVEU1R4TAABgSBKKgCFh7a7u/P1t6/ONe3bkwJG+TGxuyGsvnp2XnD8tF80en5oacQgAAOCZEoqAQassy/xw/Z7cuOKRfHdNR5pG1eblF0zPyy6YnkvmnpFacQgAAOCkEoqAQae3rz/fun9nblyxPvds3ZszxtTnt5+/MG+4tC3jx9RXezwAAIBhSygCBo2DR3rzxVVb8/ffX58tew5l7sQx+fD15+YXL5qZxlG11R4PAABg2BOKgKrbvf9w/ukHG/NPP9yUroNHc9Hs1vzedYvz/MVTPF4GAABwGglFQNVs2H0gf3fb+ty0emuO9PXneWdPyTuvnJdlcyZUezQAAIARSSgCTrvVmzpz44pH8u0HdmVUbU1+8aIZedsV83LmpOZqjwYAADCiCUXAadHfX+bmB3flxhXrs3pTZ8Y1jcq7rpqfN102J5NaGqo9HgAAABGKgFOs52hfvnzHtvz9beuzfveBzGhtyh++dHFevWxWxjT4IwgAAGAw8VMacEr095f5yl3b8qffeii79h3OuTPG5hOvvTDXnTs1dbU11R4PAACAJyAUASfd6k178sdfeyB3b92bJTPH5WOvviCXnXlGisIrmAEAAAxmQhFw0mztPJg//daafO3u7ZkytiEfe/WSvOKCGanxEvcAAABDglAEPGMHDvfmb773SG5csT5J8p5fWJBffe68jK73RwwAAMBQ4qc44Gnr7y/zb3duy5/9x8A5RC9bMj3vf9FZmdHaVO3RAAAAeBqEIuBpWbVxT/746w/knso5RH/1yxdladuEao8FAADAMyAUAU/J1s6D+ZNvPpSv37MjU8c25uO/tCQvX+IcIgAAgOFAKAJOiHOIAAAAhj8/4QFPqr+/zJfv3JY/+9ZDae8+nJdfMD2/e61ziAAAAIYjoQg4rh9t3JM//toDuXfb3iyZ1Zq/fv3SLG0bX+2xAAAAOEWEIuBnbNlzMH/yrYfyDecQAQAAjChCEZD+/jL3btub5Ws6snxte+7e0pX6upq89xcW5J3OIQIAABgx/PQHI1TngSNZsa4jy9d0ZMXajjx64EiKIjl/Zmt+45oF+aVnzcp05xABAACMKEIRjBA/vTV015aulGUyfvSoXLlwUq5aNClXLpiUM5obqj0qAAAAVSIUwTC258CR3HacraH3XLMgVy2alPNntqbW2UMAAABEKIJh5bGtoe+uac/yNR25e6utIQAAAE6cUATDwJ2bO/PPP9yU762xNQQAAMDTJxTBENXfX+bWh9pz44r1WblxT1oa6nLN2ZNtDQEAAPC0CUUwxBzu7ctX7tyWv7ttQx5u35/p4xrz3158dl5z8ew0N/hbGgAAgKfPT5UwROw9eDT/cvumfOoHG9PRfThnTxubv/ilC/Li86dlVG1NtccDAABgGBCKYJDb1nUon7xtQ/71R5tz4EhfrlgwMR979ZI8Z/7EFIVzhwAAADh5hCIYpO7fvjc3rlifr9+zI0ny0vOn5e1Xzss508dVeTIAAACGK6EIBpGyLHPbut25ccX6fP/h3RlTX5u3XDYnb3nO3Mxobar2eAAAAAxzQhEMAkf7+vONe3bkb1esz4M79mVyS0Pef+1Zed0lszOuaVS1xwMAAGCEEIqgivYf7s3nV27OP3x/Q7bv7cmCyc35s1een5dfMD0NdbXVHg8AAIARRiiCKijLMl9avTX/4+sPZF9Pby6ZOyH/7/Xn5qqFk1NT44BqAAAAqkMogtPswOHe/P5X7suX79yWS+ZOyIeuOztLZrVWeywAAAAQiuB0emD7vrz7s3dk46MH8lvPW5h3XzM/tTaIAAAAGCSEIjgNyrLMZ27fnD/++gNpbRqVz7zt0jz7zDOqPRYAAAD8BKEITrF9PUfzwZvuzTfu3ZHnLpyUj756SSY2N1R7LAAAAPgZQhGcQndv6cpvfO7ObOs6lA+86Ky844p5DqsGAABg0BKK4BQoyzL/8J8b8yfffDCTmhvyhXdemqVtE6o9FgAAADwpoQhOsq6DR/K+L96TWx7cleedPSV//qrz0zq6vtpjAQAAwM8lFMFJtGrjnrznc3emY//h/MFLFuctl89JUXjUDAAAgKFBKIKToL+/zN+seCQf/fbazGhtyk2/dlnOn9la7bEAAADgKRGK4Bnavf9wfutf78pt63bnxedNy0d+8byMbRxV7bEAAADgKROK4Bn4r0cezXs/f2e6Dh3Nh68/N6+7eLZHzQAAABiyhCJ4Gvr6y/zlrevyie+sy5yJY/Kpt1ycxdPHVnssAAAAeHlG4jcAAA9BSURBVEaEIniKdu3ryXs/f2d+uH5PbrhwRv7HK87NmAZ/KwEAADD0+ekWfo5DR/rycPv+rNnVnbW7unPT6q05eKQv/98rz88rl870qBkAAADDhlAEFUd6+7Nh94Gs2dWddbu6s2bnQBjatOdgynLga+rranLBzNZ8+Ppzs2BKS3UHBgAAgJNMKGLE6esvs3nPwazd1Z21O7sf3xRa33Egvf0DRai2psicM0Zn8fSxecWFM7JoSksWTm1J24TRqautqfLvAAAAAE4NoYhhb9OjB/Kt+3Y+HoTW7dqfw739j39+1oSmLJrSkuedPSWLprZkweSWzJs0Jo2jaqs4NQAAAJx+QhHDVn9/mX/+4aZ85JsPpudof6aMbcjCKS15/aVtj28ILZjc7CBqAAAAqPATMsPS9q5D+d0v3ZPvP7w7z104Kf/zhvMyo7Wp2mMBAADAoCYUMayUZZl/u3Nb/vCr96evv8yHrz83r7t4tlcmAwAAgBMgFDFsPLr/cD70b/fmP+7flWfNGZ8/f9WStJ0xptpjAQAAwJAhFDEsfPv+nfngl+9Nd09vPviis/K2K+altsYWEQAAADwVQhFD2r6eo/mjrz6Qm+7YmsXTxuazb78gi6a2VHssAAAAGJKEIoasHzy8O+/74t3Zua8nv3HN/PzGNQtSX1dT7bEAAABgyBKKGHIOHenLn37roXzqBxszb+KY3PRrl+XC2eOrPRYAAAAMeUIRQ8pdW7ry21+4K+s7DuTNl83J+689K031tdUeCwAAAIaFn/ucTlEUs4qi+G5RFA8WRXF/URTvrVyfUBTFzUVRrKu8HX/M93ywKIqHi6JYUxTFC4+5vrQoinsrn/tE4TXLOUFHevvzsW+vyS/+9Q/Sc6Qvn3nbJfnvLztHJAIAAICT6EQOdOlN8jtlWZ6d5NIk7yqKYnGSDyT5TlmWC5J8p/JxKp97TZJzklyb5K+Konjsp/m/TvKOJAsqv649ib8Xhqk1O7tz/V/9Zz5x68N5xQUz8q3fujKXz59Y7bEAAABg2Pm5j56VZbkjyY7K+91FUTyYZEaSlye5qvJln06yPMn7K9c/X5bl4SQbiqJ4OMnFRVFsTDK2LMv/SpKiKP4pySuSfPMk/n4YRvr6y3zy++vz5/+xNi2NdfnbNyzNC8+ZWu2xAAAAYNh6SmcUFUUxJ8mFSW5PMqUSkVKW5Y6iKCZXvmxGkh8e821bK9eOVt7/6etP9J/zjgxsHmX27NlPZUSGiS17DuZ3vnB3Vm7ckxeeMyUfvv68TGxuqPZYAAAAMKydcCgqiqI5yU1JfrMsy31PcrzQE32ifJLrP3uxLG9McmOSLFu27Am/huHrri1decs/rkxvX5mPvmpJbrhoRhxnBQAAAKfeCYWioihGZSASfaYsyy9XLu8qimJaZZtoWpL2yvWtSWYd8+0zk2yvXJ/5BNfhcSvWduRX/2V1JjY35J9+5eLMmTim2iMBAADAiHEir3pWJPlkkgfLsvzYMZ/6apI3Vd5/U5J/P+b6a4qiaCiKYm4GDq1eWXlMrbsoiksrf803HvM9kH+/a1ve+ukfpe2MMfnSrz5bJAIAAIDT7EQ2ii5P8oYk9xZFcVfl2oeS/EmSLxRF8dYkm5O8KknKsry/KIovJHkgA6+Y9q6yLPsq3/drST6VpCkDh1g7yJokyaf+c0P+6OsP5FlzJuTv3rgs45pGVXskAAAAGHGKshzcRwAtW7asXLVqVbXH4BQpyzIfv3ltPnHrw3n+4in5y9demMZRtdUeCwAAAIa1oihWl2W57KevP6VXPYOTqa+/zO//+3357O2b8+plM/M/rz8vdbU/92lIAAAA4BQRiqiKw719+c3P35Vv3rczv3bVmfndFy7yymYAAABQZUIRp113z9G8859X5wePPJr/9uKz87Yr5lV7JAAAACBCEafZ7v2H8+Z/XJmHdnTn47+0JNdfOLPaIwEAAAAVQhGnzZY9B/OGT96enft68ndvXJarz5pc7ZEAAACAYwhFnBYP7tiXN/3Dyhzu7c9n3nZplraNr/ZIAAAAwE8RijjlVm7Yk7d++kcZU1+XL/7qs7NwSku1RwIAAACegFDEKXXLA7vyrs/ekRnjm/LPb70kM1qbqj0SAAAAcBxCEafMF1dtyQe+fG/OnT42//iWizNhTH21RwIAAACehFDEKfG333skH/nmQ7liwcT8zeuXZkyDWw0AAAAGOz+9c1KVZZmPfPOh3LhifV5y/rR89NVL0lBXW+2xAAAAgBMgFHHS9Pb15/033Zub7tiaNz67LX/40nNSW1NUeywAAADgBAlFPGN9/WVWrO3I33zvkdy+YU9+63kL855fmJ+iEIkAAABgKBGKeNp27u3JF1Ztyb/+aEu2dR3KxOb6/MkN5+U1F8+u9mgAAADA0yAU8ZQ8tj302ZWbc+tD7enrL/Oc+RPzoevOzvMXT0l9XU21RwQAAACeJqGIE/JE20Nvv2JeXnvxrLSdMaba4wEAAAAngVDEcR1ve+j3Xnx2nne27SEAAAAYboQifsYTbQ+948p5ec2zbA8BAADAcCYUkeTH20OfuX1zbn1oV/rL2B4CAACAEUYoGuG2dx3Kl1Zv/YntoXc+90zbQwAAADACCUUjSH9/mbXt3Vm9qTOrN3Zm9ebObHr0YJLkigW2hwAAAGCkE4qGsQOHe3PXlq6s3tSZVZs6c+fmznT39CZJJjbXZ2nb+PzyJbPzwnOm2h4CAAAAhKLhoizLbN/bk1Ub9+SOShh6cMe+9JdJUSQLJ7fkpUumZ+ns8Vk2Z3xmTxidoiiqPTYAAAAwiAhFQ9TRvv48sH3fwGNkmwceJdu5rydJMrq+NhfObs27r56fpXMm5IJZrRnXNKrKEwMAAACDnVA0RHQdPJI7NncOPEa2sTN3b+1Kz9H+JMmM1qZcPHdClraNz9K28Tlrakvqap0zBAAAADw1QtEgVJZlNuw+kFWbOh9/jOzh9v1JktqaIudMH5vXXjz78TA0bVxTlScGAAAAhgOhaBDoOdqXe7ftzaqNAxtDd2zuzJ4DR5Ik45pG5aLZrbn+whm5aPb4LJk1LqPr/c8GAAAAnHyKQxW0d/cMbApVXqL+vm17c7SvTJLMmzgm15w1Ocsq20JnTmpOTY1DpwEAAIBTTyg6DXbsPZRbHmyvPEa2J1v2HEqS1NfVZMnMcfmV58zNsrYJuWh2a85obqjytAAAAMBIJRSdBndv6crvf+W+TGxuyLK28XnjpXOydM74nDN9bBrqaqs9HgAAAEASoei0uGLBpKz4f67OrAlNKQqPkQEAAACDk1B0GoxpqMuYBv9VAwAAAINbTbUHAAAAAGBwEIoAAAAASCIUAQAAAFAhFAEAAACQRCgCAAAAoEIoAgAAACCJUAQAAABAhVAEAAAAQBKhCAAAAIAKoQgAAACAJEIRAAAAABVCEQAAAABJhCIAAAAAKoQiAAAAAJIIRQAAAABUCEUAAAAAJBGKAAAAAKgQigAAAABIIhQBAAAAUCEUAQAAAJBEKAIAAACgQigCAAAAIIlQBAAAAECFUAQAAABAEqEIAAAAgAqhCAAAAIAkQhEAAAAAFUIRAAAAAEmEIgAAAAAqhCIAAAAAkghFAAAAAFQIRQAAAAAkEYoAAAAAqBCKAAAAAEgiFAEAAABQIRQBAAAAkEQoAgAAAKBCKAIAAAAgiVAEAAAAQIVQBAAAAEASoQgAAACACqEIAAAAgCRCEQAAAAAVQhEAAAAASYQiAAAAACqEIgAAAACSCEUAAAAAVBRlWVZ7hidVFEVHkk3VnuMkmJhkd7WHgCpx/zNSufcZydz/jFTufUYy9//Q0laW5aSfvjjoQ9FwURTFqrIsl1V7DqgG9z8jlXufkcz9z0jl3mckc/8PDx49AwAAACCJUAQAAABAhVB0+txY7QGgitz/jFTufUYy9z8jlXufkcz9Pww4owgAAACAJDaKAAAAAKgQik6DoiiuLYpiTVEUDxdF8YFqzwOnUlEU/1AURXtRFPcdc21CURQ3F0WxrvJ2fDVnhFOhKIpZRVF8tyiKB4uiuL8oivdWrrv/GdaKomgsimJlURR3V+79P6pcd+8zIhRFUVsUxZ1FUXy98rF7nxGhKIqNRVHcWxTFXUVRrKpcc/8PA0LRKVYURW2S/z/Ji5IsTvLaoigWV3cqOKU+leTan7r2gSTfKctyQZLvVD6G4aY3ye+UZXl2kkuTvKvy5737n+HucJJryrJckuSCJNcWRXFp3PuMHO9N8uAxH7v3GUmuLsvygrIsl1U+dv8PA0LRqXdxkofLslxfluWRJJ9P8vIqzwSnTFmWK5Ls+anLL0/y6cr7n07yitM6FJwGZVnuKMvyjsr73Rn4oWFG3P8Mc+WA/ZUPR1V+lXHvMwIURTEzyYuT/P0xl937jGTu/2FAKDr1ZiTZcszHWyvXYCSZUpbljmTgh+kkk6s8D5xSRVHMSXJhktvj/mcEqDx6c1eS9iQ3l2Xp3mek+Iskv5uk/5hr7n1GijLJt4uiWF0UxTsq19z/w0BdtQcYAYonuOal5gCGqaIompPclOQ3y7LcVxRP9I8BGF7KsuxLckFRFK1J/q0oinOrPROcakVRvCRJe1mWq4uiuKra80AVXF6W5faiKCYnubkoioeqPRAnh42iU29rklnHfDwzyfYqzQLVsqsoimlJUnnbXuV54JQoimJUBiLRZ8qy/HLlsvufEaMsy64kyzNwVp17n+Hu8iQvK4piYwaOl7imKIp/iXufEaIsy+2Vt+1J/i0Dx664/4cBoejU+1GSBUVRzC2Koj7Ja5J8tcozwen21SRvqrz/piT/XsVZ4JQoBlaHPpnkwbIsP3bMp9z/DGtFUUyqbBKlKIqmJM9L8lDc+wxzZVl+sCzLmWVZzsnAv+PfWpbl6+PeZwQoimJMURQtj72f5AVJ7ov7f1goytJTUKdaURTXZeD55dok/1CW5YerPBKcMkVRfC7JVUkmJtmV5A+TfCXJF5LMTrI5yavKsvzpA69hSCuK4jlJbktyb358VsWHMnBOkfufYasoivMzcGBpbQb+T8gvlGX5x0VRnBH3PiNE5dGz95Vl+RL3PiNBURTzMrBFlAwcafPZsiw/7P4fHoQiAAAAAJJ49AwAAACACqEIAAAAgCRCEQAAAAAVQhEAAAAASYQiAAAAACqEIgAAAACSCEUAAAAAVAhFAAAAACRJ/i93ZCz8UwTJqwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "point=40\n",
    "y_pred = []\n",
    "initX = X_test[point]\n",
    "model.predict(np.asarray(initX).reshape((1,14)))\n",
    "\n",
    "indx = 0\n",
    "for i in range(14):\n",
    "    newpred = []\n",
    "    for j in range(0+indx, 14):\n",
    "        newpred.append(initX[j])\n",
    "    for j in y_pred:\n",
    "        newpred.append(j)\n",
    "    indx += 1\n",
    "    y_pred.append(model.predict(np.asarray(newpred).reshape((1,14)))[0][0])\n",
    "    print(newpred)\n",
    "    \n",
    "print(y_test[point])\n",
    "print(y_test.shape[0])\n",
    "\n",
    "plotPred = []\n",
    "plotPred.append(initX[-1])\n",
    "for i in y_pred:\n",
    "    plotPred.append(i)\n",
    "\n",
    "n = point + 14\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.plot(np.arange(0,n), y_test[0:n], label=\"True\")\n",
    "plt.plot(np.arange(n-15,n), plotPred, label=\"Pred\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
